Votre demande d'addendum pour approfondir le r√©f√©rentiel `plandev-engineer` est prise en compte. 

1. Qu'est-ce qu'une Invite (Prompt) ?
Une invite est essentiellement une entr√©e fournie √† un mod√®le d'IA G√©n√©rative (GenAI) pour guider sa sortie. Ces entr√©es peuvent √™tre diverses, allant du texte simple comme ¬´ √âcris un po√®me sur les arbres ¬ª √† des formes plus complexes incluant des images, de l'audio, des vid√©os, ou une combinaison de ces modalit√©s. Bien que la composante textuelle soit pr√©dominante pour les invites actuellement, l'√©volution vers des modalit√©s non textuelles est anticip√©e.
---

### **2. Composants d'une Invite (Prompt)**

Une invite est l'entr√©e fournie √† un mod√®le d'IA G√©n√©rative (GenAI) pour guider sa sortie. Pour construire des invites efficaces, il est crucial de comprendre leurs composants fondamentaux. Ces composants aident √† structurer l'entr√©e de mani√®re √† maximiser la pertinence et la qualit√© de la r√©ponse du mod√®le, un aspect vital pour la granularisation et l'actionnabilit√© des roadmaps dans le mode `plandev-engineer`.

*   **Directive**
    La directive est l'**intention principale de l'invite, souvent sous forme d'instruction ou de question**. C'est le c≈ìur de ce que l'on attend du mod√®le. Dans le contexte du mode `plandev-engineer`, les directives sont cruciales pour transformer un plan de d√©veloppement en une feuille de route actionnable et exhaustive.

    Exemple de directive explicite:
    `Dis-moi cinq bons livres √† lire.`

    Les directives peuvent √©galement √™tre implicites, comme dans le cas d'un "one-shot" o√π la t√¢che est d√©duite de l'exemple.
    Pour `plandev-engineer`, la directive principale est toujours implicitement "transforme tout plan de d√©veloppement en une feuille de route exhaustive, actionnable, automatisable, test√©e, tra√ßable et continuellement raffin√©e, align√©e sur les standards Roo Code et le mode `plandev-engineer`". Cependant, chaque section du prompt avanc√© contient des directives sp√©cifiques pour les sous-t√¢ches, comme "Avant toute g√©n√©ration, analyse le contexte, les objectifs...".

*   **Exemples (Exemplars ou Shots)**
    Les exemples sont des **d√©monstrations qui guident la GenAI pour accomplir une t√¢che**. Ils sont particuli√®rement importants pour l'apprentissage en contexte (In-Context Learning - ICL), qui permet au mod√®le d'apprendre des comp√©tences sans mise √† jour des poids. Pour `plandev-engineer`, l'utilisation d'exemples peut affiner la g√©n√©ration de phases, de t√¢ches et de scripts, assurant l'alignement avec les standards Roo Code.

    Un exemple "One-Shot":
    `Nuit: Noche Matin:`
    L'exemple ci-dessus indique au mod√®le de traduire de l'anglais vers l'espagnol, et le mod√®le devrait r√©pondre "Ma√±ana".
    Le r√©f√©rentiel `plandev-engineer` lui-m√™me contient un "Exemple de structure avanc√©e" qui sert d'exemplaire pour la g√©n√©ration des roadmaps.

*   **Formatage de la Sortie (Output Formatting)**
    Il est souvent souhaitable que la GenAI produise des informations dans des **formats sp√©cifiques, tels que CSV, Markdown, XML ou m√™me des formats personnalis√©s**. Bien que cela puisse parfois r√©duire les performances sur certaines t√¢ches, cela peut aussi les am√©liorer. Le mode `plandev-engineer` insiste sur un format de sortie enrichi en Markdown Roo.

    Exemple de formatage de sortie en CSV:
    `{PARAGRAPHE} R√©sume cela en un fichier CSV.`
    Pour les roadmaps `plandev-engineer`, le format Markdown Roo est sp√©cifi√© pour les "Phases", "T√¢ches actionnables", "Scripts/Commandes", "Fichiers attendus", "Crit√®res de validation", etc..

*   **Instructions de Style (Style Instructions)**
    Les instructions de style sont un type de formatage de sortie utilis√© pour **modifier stylistiquement plut√¥t que structurellement la sortie**. Elles peuvent influencer le ton, le genre ou la formulation du texte g√©n√©r√©.

    Exemple d'instruction de style:
    `√âcris un paragraphe clair et concis sur les lamas.`

*   **R√¥le (Role ou Persona)**
    Un r√¥le, √©galement connu sous le nom de persona, est un composant fr√©quemment utilis√© qui peut **am√©liorer la r√©daction et le style du texte**. Cela consiste √† assigner un r√¥le sp√©cifique √† la GenAI dans l'invite.

    Exemple de d√©finition de r√¥le:
    `Fais semblant d'√™tre un berger et √©cris un limerick sur les lamas.`
    Dans le prompt avanc√© de `plandev-engineer`, le mod√®le est instruit d'agir en tant qu'**"architecte logiciel principal, expert Go, CI/CD, TDD, observabilit√©, GenAI, ing√©nierie des prompts et alignement IA"**. Ce r√¥le sp√©cifique fa√ßonne non seulement le style, mais aussi l'expertise technique et l'approche de d√©composition et de justification des t√¢ches.

*   **Informations Additionnelles (Additional Information)**
    Il est souvent n√©cessaire d'inclure des informations suppl√©mentaires dans l'invite pour aider la GenAI √† g√©n√©rer une r√©ponse appropri√©e. Bien que parfois appel√© "contexte", ce terme est d√©conseill√© en raison de ses significations multiples dans le domaine de l'ing√©nierie des invites. Ces informations aident √† contextualiser la demande.

    Exemple d'informations additionnelles:
    Si la directive est d'√©crire un e-mail, on peut inclure le nom et la position pour que la GenAI puisse signer correctement l'e-mail.
    Pour le mode `plandev-engineer`, l'analyse syst√©matique du "contexte, les objectifs, les contraintes, les d√©pendances et les zones d‚Äôambigu√Øt√©" avant toute g√©n√©ration constitue une forme cruciale d'informations additionnelles pour le mod√®le, lui permettant de cr√©er des roadmaps sp√©cifiques et pertinentes. L'email du professeur dans l'√©tude de cas est un exemple r√©el de la fa√ßon dont un "contexte" plus riche peut am√©liorer les performances.

---

> **üõ†Ô∏è Adaptation par mode Roo**
>
> - **plandev-engineer**‚ÄØ: Chaque composant de prompt doit √™tre align√© sur la structure Roo (phases, t√¢ches, scripts, validation, rollback, etc.). Voir le r√©f√©rentiel [`plandev-engineer-reference.md`](.roo/rules/rules-plandev-engineer/plandev-engineer-reference.md:1).
> - **orchestrator**‚ÄØ: Les prompts doivent permettre la d√©l√©gation multi-modes et la tra√ßabilit√© des sous-t√¢ches. Voir [`rules-orchestration.md`](.roo/rules/rules-orchestration.md:1).
> - **debug**‚ÄØ: Les invites doivent guider la reproduction, l‚Äôisolation et la documentation des bugs. Voir [`rules-debug.md`](.roo/rules/rules-debug.md:1).
> - **documentation-writer**‚ÄØ: Privil√©gier la clart√©, la modularit√© et l‚Äôint√©gration de liens crois√©s. Voir [`rules-documentation.md`](.roo/rules/rules-documentation.md:1).
>
> **üîó Liens Roo utiles**‚ÄØ:  
> - [Principes transverses Roo](.roo/rules/rules.md:1)  
> - [AGENTS.md](AGENTS.md:1)  
> - [workflows-matrix.md](.roo/rules/workflows-matrix.md:1)
### **3. Processus d'Ing√©nierie des Invites (Prompt Engineering)**

L'ing√©nierie des invites (Prompt Engineering) est le **processus it√©ratif de d√©veloppement d'une invite en modifiant ou en changeant la technique d'invitation utilis√©e**. Ce processus est fondamental pour le mode `plandev-engineer`, qui vise des feuilles de route "continuellement raffin√©es".

*   **Nature It√©rative**
    L'ing√©nierie des invites est intrins√®quement un **processus cyclique**. Elle implique de tester une invite, d'√©valuer sa performance et de la modifier pour l'am√©liorer. Cette approche it√©rative est en ligne avec les principes de raffinement continu et d'auto-critique du r√©f√©rentiel `plandev-engineer`.

    Le processus se compose de trois √©tapes r√©p√©t√©es:
    1.  **R√©aliser l'inf√©rence sur un jeu de donn√©es**: Le mod√®le g√©n√®re des sorties bas√©es sur l'invite.
    2.  **√âvaluer les performances**: Les sorties sont √©valu√©es par rapport aux crit√®res souhait√©s (par exemple, la pr√©cision, la conformit√© au format).
    3.  **Modifier la template de l'invite**: L'invite est ajust√©e en fonction des r√©sultats de l'√©valuation.

> **üõ†Ô∏è Adaptation par mode Roo**
>
> - **plandev-engineer**‚ÄØ: Le cycle d‚Äôit√©ration sur les prompts doit int√©grer explicitement les phases d‚Äôauto-critique, de validation crois√©e et de raffinement continu, conform√©ment au r√©f√©rentiel [`plandev-engineer-reference.md`](.roo/rules/rules-plandev-engineer/plandev-engineer-reference.md:1). Chaque modification de prompt doit √™tre document√©e et test√©e sur des cas r√©els de g√©n√©ration de roadmap.
> - **orchestrator**‚ÄØ: L‚Äôit√©ration sur les prompts doit permettre la coordination entre modes, la tra√ßabilit√© des ajustements et la synchronisation des sous-t√¢ches. Voir [`rules-orchestration.md`](.roo/rules/rules-orchestration.md:1).
> - **debug**‚ÄØ: Le processus d‚Äôit√©ration doit inclure la reproduction syst√©matique des bugs, la documentation des hypoth√®ses et la validation par tests unitaires. Voir [`rules-debug.md`](.roo/rules/rules-debug.md:1).
> - **documentation-writer**‚ÄØ: Privil√©gier la tra√ßabilit√© des versions de prompts, l‚Äôint√©gration de feedback utilisateur et la clart√© des changements apport√©s. Voir [`rules-documentation.md`](.roo/rules/rules-documentation.md:1).
>
> **üîó Liens Roo utiles**‚ÄØ:  
> - [Principes transverses Roo](.roo/rules/rules.md:1)  
> - [AGENTS.md](AGENTS.md:1)  
> - [workflows-matrix.md](.roo/rules/workflows-matrix.md:1)
    Pour `plandev-engineer`, cela signifie que les prompts g√©n√©rant les roadmaps doivent √™tre r√©guli√®rement √©valu√©s pour leur granularit√©, leur actionnabilit√©, leur tra√ßabilit√© et leur alignement. La section "Auto-critique & raffinement" du prompt avanc√© encourage explicitement ce cycle en sugg√©rant des am√©liorations et en demandant un feedback.

    Exemple du processus it√©ratif issu de l'√©tude de cas sur la d√©tection de l'entrapment:
    Le processus a impliqu√© **47 √©tapes de d√©veloppement enregistr√©es**, cumulant environ 20 heures de travail, avec des scores F1 variant consid√©rablement. Cela d√©montre la nature it√©rative et exploratoire de l'ing√©nierie des invites, o√π des ajustements mineurs peuvent avoir un impact significatif sur la performance.

---

### **4. Apprentissage en Contexte (In-Context Learning - ICL)**

> **üõ†Ô∏è Adaptation Roo-Code par mode¬†:**
>
> - **plandev-engineer**‚ÄØ: L‚ÄôICL est utilis√© pour fournir des exemples structur√©s de phases, t√¢ches et crit√®res de validation. Les prompts doivent int√©grer des exemplaires issus du r√©f√©rentiel [`plandev-engineer-reference.md`](.roo/rules/rules-plandev-engineer/plandev-engineer-reference.md:1).
> - **orchestrator**‚ÄØ: Les exemples doivent illustrer la d√©l√©gation multi-modes et la synchronisation des sous-t√¢ches ([rules-orchestration.md](.roo/rules/rules-orchestration.md:1)).
> - **debug**‚ÄØ: Utiliser des exemples de sc√©narios d‚Äôerreur et de r√©solution pour guider la reproduction et la correction ([rules-debug.md](.roo/rules/rules-debug.md:1)).
> - **documentation-writer**‚ÄØ: Illustrer chaque technique par des exemples concrets et des liens crois√©s ([rules-documentation.md](.roo/rules/rules-documentation.md:1)).
>
> **üîó Liens Roo utiles**¬†:
> - [Principes transverses Roo](.roo/rules/rules.md:1)
> - [AGENTS.md](AGENTS.md:1)
> - [workflows-matrix.md](.roo/rules/workflows-matrix.md:1)

L'Apprentissage en Contexte (ICL) fait r√©f√©rence √† la **capacit√© des GenAI √† acqu√©rir des comp√©tences et des t√¢ches en leur fournissant des exemples (exemplars) et/ou des instructions pertinentes directement dans l'invite, sans n√©cessiter de mises √† jour de poids ou de r√©entra√Ænement**. L'ICL peut simplement √™tre une sp√©cification de t√¢che, o√π les comp√©tences ne sont pas n√©cessairement nouvelles mais ont d√©j√† √©t√© incluses dans les donn√©es d'entra√Ænement.

*   **D√©finition et types (Zero-Shot, One-Shot, Few-Shot)**
    L'ICL englobe diff√©rentes approches selon le nombre d'exemples fournis:
    *   **Zero-Shot Prompting**: N'utilise **aucun exemple**. Le mod√®le pr√©dit la r√©ponse en se basant uniquement sur une description en langage naturel de la t√¢che.
        Exemple:
        `Traduire l'anglais vers le fran√ßais: cheese`
        Le mod√®le est cens√© comprendre la t√¢che sans avoir vu d'exemples de traduction.

    *   **One-Shot Prompting**: Inclut un **unique exemple** de la t√¢che dans l'invite.
        Exemple:
        `Night: Noche Morning:`
        Le mod√®le d√©duit de cet unique exemple qu'il doit traduire le mot "Morning".

    *   **Few-Shot Prompting**: Fournit un **petit nombre d'exemples** (g√©n√©ralement de 10 √† 100) pour guider le mod√®le.
        Exemple:
        `2+2: four 4+5: nine 8+0:`
        Le mod√®le utilise ces exemples pour apprendre le format et le type de r√©ponse attendue.
        Dans le contexte de `plandev-engineer`, l'int√©gration d'exemplaires dans le prompt (comme la "structure avanc√©e" ou les "exemples de section") peut grandement am√©liorer la conformit√© et la qualit√© des roadmaps g√©n√©r√©es en montrant au mod√®le la forme et le contenu attendus pour les t√¢ches, les livrables et les crit√®res de validation.

*   **D√©cisions de Conception pour le Few-Shot Prompting**
    La s√©lection des exemples pour une invite "few-shot" est complexe et d√©pend de plusieurs facteurs qui influencent la qualit√© de la sortie.

    *   **Quantit√© d'Exemplaires**
        **Augmenter la quantit√© d'exemplaires am√©liore g√©n√©ralement les performances du mod√®le**, surtout pour les grands mod√®les. Cependant, les avantages peuvent diminuer au-del√† d'une vingtaine d'exemplaires. Pour les LLM avec des contextes longs, des exemplaires suppl√©mentaires continuent d'am√©liorer les performances, mais l'efficacit√© varie selon la t√¢che.

    *   **Ordre des Exemplaires**
        L'ordre des exemplaires affecte le comportement du mod√®le. Sur certaines t√¢ches, **l'ordre peut faire varier la pr√©cision de moins de 50% √† plus de 90%**. Cela souligne l'importance de l'exp√©rimentation avec l'ordre des exemples pour `plandev-engineer` afin d'optimiser la g√©n√©ration de roadmaps.

    *   **Distribution des Labels des Exemplaires**
        Comme en apprentissage automatique supervis√© traditionnel, la distribution des labels des exemples dans l'invite affecte le comportement. Une distribution d√©s√©quilibr√©e peut **biaiser le mod√®le** vers la classe surrepr√©sent√©e.

    *   **Qualit√© des Labels des Exemplaires**
        La n√©cessit√© de d√©monstrations strictement valides n'est pas toujours claire. Certains travaux sugg√®rent que l'exactitude des labels est sans importance, tandis que d'autres montrent un impact significatif sur les performances dans certains contextes. Les mod√®les plus grands g√®rent mieux les labels incorrects ou non pertinents.

    *   **Format des Exemplaires**
        Le format des exemplaires affecte √©galement les performances. Un format courant est "Q: {input}, A: {label}", mais le format optimal peut varier. Les formats courants dans les donn√©es d'entra√Ænement tendent √† mieux fonctionner. Les exemples de structure dans `plandev-engineer` fournissent un format clair pour les t√¢ches et les livrables.

    *   **Similitude des Exemplaires**
        **S√©lectionner des exemplaires similaires √† l'√©chantillon de test est g√©n√©ralement b√©n√©fique**. Cependant, dans certains cas, des exemplaires plus diversifi√©s peuvent am√©liorer les performances.

    *   **S√©lection des Instructions**
        Bien que les instructions soient n√©cessaires pour guider les LLM en "zero-shot", les b√©n√©fices d'ajouter des instructions avant les exemples en "few-shot" sont moins clairs. Des instructions g√©n√©riques peuvent am√©liorer la pr√©cision de la classification et de la r√©ponse aux questions par rapport √† des instructions sp√©cifiques √† la t√¢che.

*   **Techniques de Few-Shot Prompting**
    Pour une impl√©mentation efficace du Few-Shot Prompting, diverses techniques ont √©t√© d√©velopp√©es:

    *   **K-Nearest Neighbor (KNN)**: S√©lectionne des exemplaires similaires √† l'√©chantillon de test pour am√©liorer la performance. Efficace, mais peut √™tre co√ªteux en temps et en ressources.
    *   **Vote-K**: Une m√©thode pour s√©lectionner des exemplaires similaires, o√π un mod√®le propose des candidats non √©tiquet√©s pour l'annotation, puis les exemplaires √©tiquet√©s sont utilis√©s pour le Few-Shot Prompting. Assure √©galement la diversit√© des exemplaires.
    *   **Self-Generated In-Context Learning (SG-ICL)**: Utilise une GenAI pour g√©n√©rer automatiquement des exemplaires. Moins efficace que les donn√©es r√©elles, mais utile si les donn√©es d'entra√Ænement ne sont pas disponibles.
    *   **Prompt Mining**: Processus de d√©couverte des "mots interm√©diaires" optimaux dans les invites via l'analyse de corpus. Les formats plus fr√©quents dans le corpus am√©liorent la performance.

*   **Techniques de Zero-Shot Prompting**
    Ces techniques n'utilisent aucun exemplaire et se basent uniquement sur l'instruction.

    *   **Role Prompting** (ou Persona Prompting): **Assigne un r√¥le sp√©cifique √† la GenAI** dans l'invite (par exemple, "agir comme Madonna" ou "un √©crivain de voyage"). Peut cr√©er des sorties plus d√©sirables pour les t√¢ches ouvertes et parfois am√©liorer la pr√©cision.
        Ceci est directement appliqu√© dans le prompt `plandev-engineer` en instruisant le mod√®le d'agir en tant qu'architecte logiciel principal.

    *   **Style Prompting**: Sp√©cifie le style, le ton ou le genre souhait√© dans l'invite pour fa√ßonner la sortie. Un effet similaire peut √™tre obtenu avec le r√¥le.

    *   **Emotion Prompting**: Int√®gre des phrases de pertinence psychologique (par exemple, "Ceci est important pour ma carri√®re") dans l'invite pour potentiellement am√©liorer les performances des LLM.

    *   **System 2 Attention (S2A)**: Demande d'abord √† un LLM de r√©√©crire l'invite en supprimant les informations non pertinentes, puis passe cette nouvelle invite √† un autre LLM pour la r√©ponse finale.

    *   **SimToM**: Traite les questions complexes impliquant plusieurs personnes ou objets en √©tablissant l'ensemble des faits qu'une personne conna√Æt, puis r√©pond en se basant uniquement sur ces faits.

    *   **Rephrase and Respond (RaR)**: Demande au LLM de paraphraser et d'√©largir la question avant de g√©n√©rer la r√©ponse finale. A d√©montr√© des am√©liorations sur plusieurs benchmarks.

    *   **Re-reading (RE2)**: Ajoute la phrase "Relisez la question:" √† l'invite en plus de r√©p√©ter la question. Malgr√© sa simplicit√©, a montr√© une am√©lioration dans les benchmarks de raisonnement.
        L'√©tude de cas a accidentellement d√©couvert un effet similaire en dupliquant un email de contexte, ce qui a eu des effets positifs significatifs sur les performances.

    *   **Self-Ask**: Demande aux LLM de d√©cider d'abord s'ils ont besoin de poser des questions de suivi, puis de g√©n√©rer et de r√©pondre √† ces questions avant de r√©pondre √† la question originale.

---

### **5. G√©n√©ration de Pens√©e (Thought Generation)**

> **üõ†Ô∏è Adaptation Roo-Code par mode¬†:**
>
> - **plandev-engineer**‚ÄØ: Les prompts doivent inciter √† la justification d√©taill√©e (CoT, arbitrages, alternatives) pour chaque phase de roadmap ([plandev-engineer-reference.md](.roo/rules/rules-plandev-engineer/plandev-engineer-reference.md:1)).
> - **orchestrator**‚ÄØ: Favoriser la tra√ßabilit√© du raisonnement lors de l‚Äôagr√©gation des sous-t√¢ches ([rules-orchestration.md](.roo/rules/rules-orchestration.md:1)).
> - **debug**‚ÄØ: Utiliser le raisonnement √©tape par √©tape pour documenter la r√©solution des bugs ([rules-debug.md](.roo/rules/rules-debug.md:1)).
> - **documentation-writer**‚ÄØ: Expliquer les choix structurants et les alternatives dans les guides ([rules-documentation.md](.roo/rules/rules-documentation.md:1)).
>
> **üîó Liens Roo utiles**¬†:
> - [Principes transverses Roo](.roo/rules/rules.md:1)
> - [AGENTS.md](AGENTS.md:1)
> - [workflows-matrix.md](.roo/rules/workflows-matrix.md:1)

La g√©n√©ration de pens√©e englobe une gamme de techniques qui incitent le LLM √† **articuler son raisonnement tout en r√©solvant un probl√®me**. Ces techniques sont directement align√©es avec la demande du mode `plandev-engineer` de d√©composer les objectifs en phases logiques et sous-t√¢ches atomiques, en explicitant les justifications (CoT, arbitrages).

*   **Chain-of-Thought (CoT) Prompting**
    Le CoT Prompting **tire parti du "few-shot prompting" pour encourager le LLM √† exprimer son processus de pens√©e avant de donner sa r√©ponse finale**. Cette technique am√©liore significativement les performances des LLM dans les t√¢ches de math√©matiques et de raisonnement. Un prompt CoT inclut un exemple avec une question, un chemin de raisonnement et la bonne r√©ponse.

    Exemple de prompt CoT One-Shot:
    `Q: Jack a deux paniers, chacun contenant trois balles. Combien de balles Jack a-t-il en tout? R: Un panier contient 3 balles, donc deux paniers contiennent 3 * 2 = 6 balles. Q: {QUESTION} R:`

*   **Zero-Shot CoT**
    La version la plus simple du CoT ne contient **aucun exemple**. Elle consiste √† **ajouter une phrase incitant √† la r√©flexion** comme "R√©fl√©chissons √©tape par √©tape." √† l'invite.

    Exemple:
    `R√©fl√©chissons √©tape par √©tape.`
    Cette technique est attrayante car elle ne n√©cessite pas d'exemplaires et est g√©n√©ralement agnostique √† la t√¢che.

    *   **Step-Back Prompting**: Modification du CoT o√π le LLM est d'abord interrog√© sur des concepts ou faits pertinents de haut niveau avant d'aborder le raisonnement d√©taill√©. A am√©lior√© les performances sur plusieurs benchmarks de raisonnement.
    *   **Analogical Prompting**: G√©n√®re automatiquement des exemples incluant des cha√Ænes de pens√©e (CoT). A d√©montr√© des am√©liorations dans le raisonnement math√©matique et la g√©n√©ration de code.
    *   **Thread-of-Thought (ThoT) Prompting**: Une phrase d'incitation √† la pens√©e am√©lior√©e pour le raisonnement CoT, comme "Parcourez ce contexte en parties g√©rables √©tape par √©tape, en r√©sumant et en analysant au fur et √† mesure.". Efficace pour la r√©ponse aux questions et la r√©cup√©ration.
    *   **Tabular Chain-of-Thought (Tab-CoT)**: Un prompt Zero-Shot CoT qui fait en sorte que le LLM produise son raisonnement sous forme de tableau Markdown. Cette conception tabulaire am√©liore la structure et donc le raisonnement de la sortie.
        La structuration en tableau est un format privil√©gi√© par le mode `plandev-engineer` pour les informations.

*   **Few-Shot CoT**
    Cet ensemble de techniques pr√©sente au LLM **plusieurs exemplaires qui incluent des cha√Ænes de pens√©e**, ce qui peut significativement am√©liorer les performances.

    *   **Contrastive CoT Prompting**: Ajoute des exemples avec des explications incorrectes et correctes au prompt CoT pour montrer au LLM comment *ne pas* raisonner. A montr√© une am√©lioration significative dans l'arithm√©tique et la QA factuelle.
    *   **Uncertainty-Routed CoT Prompting**: √âchantillonne plusieurs chemins de raisonnement CoT, puis s√©lectionne la majorit√© si elle d√©passe un certain seuil.
    *   **Complexity-based Prompting**: S√©lectionne des exemples complexes pour l'annotation et l'inclusion dans le prompt, et √©chantillonne plusieurs cha√Ænes de raisonnement en utilisant un vote majoritaire.
    *   **Active Prompting**: Commence avec des questions/exemplaires d'entra√Ænement, demande au LLM de les r√©soudre, calcule l'incertitude, et demande √† des annotateurs humains de r√©√©crire les exemplaires avec la plus grande incertitude.
    *   **Memory-of-Thought Prompting**: Utilise des exemplaires d'entra√Ænement non √©tiquet√©s pour construire des prompts Few-Shot CoT au moment du test.
    *   **Automatic Chain-of-Thought (Auto-CoT) Prompting**: Utilise un prompt Zero-Shot pour g√©n√©rer automatiquement des cha√Ænes de pens√©e, qui sont ensuite utilis√©es pour construire un prompt Few-Shot CoT.
        L'√©tude de cas a utilis√© AutoDiCoT, une variation d'Auto-CoT, pour g√©n√©rer des explications et am√©liorer le prompt.

---

### **6. D√©composition (Decomposition)**

> **üõ†Ô∏è Adaptation Roo-Code par mode¬†:**
>
> - **plandev-engineer**‚ÄØ: La d√©composition en phases logiques et t√¢ches atomiques est obligatoire pour chaque plan ([plandev-engineer-reference.md](.roo/rules/rules-plandev-engineer/plandev-engineer-reference.md:1)).
> - **orchestrator**‚ÄØ: D√©couper les t√¢ches complexes en sous-t√¢ches actionnables et d√©l√©guer √† chaque mode ([rules-orchestration.md](.roo/rules/rules-orchestration.md:1)).
> - **debug**‚ÄØ: D√©composer les bugs en √©tapes de reproduction et de correction ([rules-debug.md](.roo/rules/rules-debug.md:1)).
> - **documentation-writer**‚ÄØ: Structurer les guides en √©tapes s√©quentielles et actionnables ([rules-documentation.md](.roo/rules/rules-documentation.md:1)).
>
> **üîó Liens Roo utiles**¬†:
> - [Principes transverses Roo](.roo/rules/rules.md:1)
> - [AGENTS.md](AGENTS.md:1)
> - [workflows-matrix.md](.roo/rules/workflows-matrix.md:1)

La d√©composition est une strat√©gie de r√©solution de probl√®mes qui **transforme des probl√®mes complexes en sous-questions plus simples**. Ceci est explicitement demand√© dans le prompt avanc√© de `plandev-engineer` sous "D√©composition avanc√©e".

*   **Least-to-Most Prompting**: Demande √† un LLM de d√©composer un probl√®me en sous-probl√®mes sans les r√©soudre initialement, puis de les r√©soudre s√©quentiellement en ajoutant les r√©ponses du mod√®le √† l'invite √† chaque fois. A montr√© des am√©liorations significatives dans les t√¢ches de manipulation symbolique et de raisonnement math√©matique.
*   **Decomposed Prompting (DECOMP)**: Utilise le Few-Shot Prompting pour montrer √† un LLM comment utiliser certaines fonctions (par exemple, le fractionnement de cha√Ænes, la recherche sur Internet). Le LLM d√©compose alors son probl√®me original en sous-probl√®mes qu'il envoie √† diff√©rentes fonctions.
*   **Plan-and-Solve Prompting**: Un prompt Zero-Shot CoT am√©lior√©, "Commen√ßons par comprendre le probl√®me et √©laborons un plan pour le r√©soudre. Ensuite, ex√©cutons le plan et r√©solvons le probl√®me √©tape par √©tape". G√©n√®re des processus de raisonnement plus robustes.
    Cela r√©sonne fortement avec la structuration des roadmaps `plandev-engineer` en phases logiques et t√¢ches atomiques.

*   **Tree-of-Thought (ToT)**: Cr√©e un probl√®me de recherche arborescent en g√©n√©rant plusieurs √©tapes possibles sous forme de pens√©es (comme √† partir d'un CoT). √âvalue la progression de chaque √©tape vers la r√©solution du probl√®me et d√©cide quelles √©tapes poursuivre. Tr√®s efficace pour les t√¢ches n√©cessitant recherche et planification.
*   **Recursion-of-Thought**: Similaire au CoT, mais chaque fois qu'un probl√®me compliqu√© est rencontr√© au milieu de la cha√Æne de raisonnement, il est envoy√© dans une autre invite/appel LLM, puis la r√©ponse est ins√©r√©e dans l'invite originale. Permet de r√©soudre r√©cursivement des probl√®mes complexes.
*   **Program-of-Thoughts (PAL)**: Utilise les LLM pour g√©n√©rer du code de programmation comme √©tapes de raisonnement, ex√©cut√© par un interpr√©teur de code pour obtenir la r√©ponse finale. Excellente pour les t√¢ches math√©matiques et de programmation.
    Cela s'aligne avec la section "Scripts/Commandes" du mode `plandev-engineer`.

*   **Faithful Chain-of-Thought**: G√©n√®re un CoT qui contient un raisonnement en langage naturel et symbolique (par exemple, Python), utilisant diff√©rents types de langages symboliques en fonction de la t√¢che.
*   **Skeleton-of-Thought**: Acc√©l√®re la vitesse de r√©ponse par la parall√©lisation. Un LLM cr√©e un squelette de la r√©ponse (sous-probl√®mes √† r√©soudre), puis ces questions sont envoy√©es en parall√®le √† un LLM et les sorties sont concat√©n√©es pour une r√©ponse finale.
*   **Metacognitive Prompting**: Tente de faire en sorte que le LLM reproduise les processus m√©tacognitifs humains avec une cha√Æne d'invites en cinq parties, incluant la clarification de la question, le jugement pr√©liminaire, l'√©valuation de la r√©ponse, la confirmation de la d√©cision et l'√©valuation de la confiance.

---

### **7. Auto-Critique (Self-Criticism)**

> **üõ†Ô∏è Adaptation Roo-Code par mode¬†:**
>
> - **plandev-engineer**‚ÄØ: L‚Äôauto-critique et le raffinement sont requis en fin de chaque phase, avec boucle de feedback utilisateur ([plandev-engineer-reference.md](.roo/rules/rules-plandev-engineer/plandev-engineer-reference.md:1)).
> - **orchestrator**‚ÄØ: Appliquer l‚Äôauto-critique √† la synth√®se globale des r√©sultats ([rules-orchestration.md](.roo/rules/rules-orchestration.md:1)).
> - **debug**‚ÄØ: Utiliser Self-Verification pour valider la correction et documenter les limites ([rules-debug.md](.roo/rules/rules-debug.md:1)).
> - **documentation-writer**‚ÄØ: Int√©grer une boucle de relecture syst√©matique et de calibration documentaire ([rules-documentation.md](.roo/rules/rules-documentation.md:1)).
>
> **üîó Liens Roo utiles**¬†:
> - [Principes transverses Roo](.roo/rules/rules.md:1)
> - [AGENTS.md](AGENTS.md:1)
> - [workflows-matrix.md](.roo/rules/workflows-matrix.md:1)

L'auto-critique implique que les LLM **critiquent leurs propres sorties**. Cela peut √™tre un jugement (par exemple, si la sortie est correcte) ou un retour d'information pour am√©liorer la r√©ponse. Cette capacit√© est directement li√©e √† la section "Auto-critique & raffinement" du prompt [`plandev-engineer`](.roo/rules/rules-plandev-engineer/plandev-engineer-reference.md#version-avanc√©e-du-prompt), qui vise √† identifier les limites du plan et les axes d'am√©lioration continue.

*   **Self-Calibration**: Demande √† un LLM de r√©pondre √† une question, puis construit une nouvelle invite incluant la question, la r√©ponse du LLM et une instruction suppl√©mentaire demandant si la r√©ponse est correcte. Utile pour √©valuer les niveaux de confiance.
*   **Self-Refine**: Un cadre it√©ratif o√π, apr√®s une premi√®re r√©ponse, le m√™me LLM est invit√© √† fournir un feedback sur cette r√©ponse, puis √† l'am√©liorer en fonction du feedback. Ce processus it√©ratif se poursuit jusqu'√† une condition d'arr√™t. A d√©montr√© des am√©liorations dans les t√¢ches de raisonnement, de codage et de g√©n√©ration.
*   **Reversing Chain-of-Thought (RCoT)**: Demande aux LLM de reconstruire le probl√®me √† partir d'une r√©ponse g√©n√©r√©e, puis g√©n√®re des comparaisons fines entre le probl√®me original et le probl√®me reconstruit pour v√©rifier les incoh√©rences. Ces incoh√©rences sont ensuite converties en feedback pour r√©viser la r√©ponse.
*   **Self-Verification**: G√©n√®re plusieurs solutions candidates avec CoT, puis √©value chaque solution en masquant certaines parties de la question originale et en demandant √† un LLM de les pr√©dire en se basant sur le reste de la question et la solution g√©n√©r√©e.
*   **Chain-of-Verification (COVE)**: Utilise d'abord un LLM pour g√©n√©rer une r√©ponse, puis cr√©e une liste de questions connexes pour v√©rifier la justesse de la r√©ponse. Chaque question est ensuite trait√©e par le LLM, et toutes les informations sont utilis√©es pour produire la r√©ponse finale r√©vis√©e.
*   **Cumulative Reasoning**: G√©n√®re plusieurs √©tapes potentielles pour r√©pondre √† une question, fait √©valuer ces √©tapes par un LLM (acceptation/rejet), et v√©rifie si la r√©ponse finale a √©t√© atteinte. A d√©montr√© des am√©liorations dans les t√¢ches d'inf√©rence logique et de probl√®mes math√©matiques.

> **üõ†Ô∏è Adaptation Roo-Code par mode¬†:**
>
> - **plandev-engineer**¬†: L‚Äôauto-critique est obligatoire en fin de chaque phase (voir [exemple de structure avanc√©e](.roo/rules/rules-plandev-engineer/plandev-engineer-reference.md#exemple-de-structure-avanc√©e)). Utiliser Self-Refine ou COVE pour g√©n√©rer des suggestions d‚Äôam√©lioration continue.
> - **orchestrator**¬†: L‚Äôauto-critique doit √™tre appliqu√©e √† la synth√®se globale, en croisant les r√©sultats des sous-t√¢ches (voir [rules-orchestration.md](.roo/rules/rules-orchestration.md)).
> - **debug**¬†: Privil√©gier Self-Verification pour valider la correction des bugs et documenter les limites dans la checklist de d√©bogage ([rules-debug.md](.roo/rules/rules-debug.md)).
> - **documentation-writer**¬†: Int√©grer une boucle de relecture/raffinement syst√©matique, en s‚Äôappuyant sur Self-Calibration pour garantir la clart√© documentaire ([rules-documentation.md](.roo/rules/rules-documentation.md)).

---

### **8. Probl√®mes d'Alignement: Sensibilit√© des Invites et Biais**

L'alignement est essentiel pour s'assurer que les LLM r√©pondent aux besoins des utilisateurs sans produire de contenu nuisible, de r√©ponses incoh√©rentes ou de biais. Le r√©f√©rentiel [`plandev-engineer`](.roo/rules/rules-plandev-engineer/plandev-engineer-reference.md#version-avanc√©e-du-prompt) aborde explicitement ces risques dans sa section "Risques & mitigation" et met l'accent sur l'alignement IA dans ses techniques d'ing√©nierie de prompt.

*   **Sensibilit√© des Invites (Prompt Sensitivity)**
    Les LLM sont **tr√®s sensibles √† l'invite d'entr√©e**, m√™me de subtils changements pouvant entra√Æner des sorties tr√®s diff√©rentes.

    *   **Petits Changements dans l'Invite**: Des modifications mineures comme des espaces suppl√©mentaires, des changements de majuscules, des modifications de d√©limiteurs ou des remplacements de synonymes peuvent impacter significativement les performances. Par exemple, pour LLaMA2-7B, de petits changements peuvent faire varier les performances de pr√®s de 0 √† 0.804 sur certaines t√¢ches.

    *   **Format de la T√¢che (Task Format)**: Diff√©rentes mani√®res de formuler la m√™me t√¢che (par exemple, "classer une critique comme 'positive' ou 'n√©gative'" vs. "Est-ce que cette critique est positive?" pour une r√©ponse "oui" ou "non") peuvent modifier la pr√©cision de GPT-3 jusqu'√† 30%.

    *   **D√©rive de l'Invite (Prompt Drift)**: Se produit lorsque le mod√®le derri√®re une API change au fil du temps, de sorte que la m√™me invite peut produire des r√©sultats diff√©rents sur le mod√®le mis √† jour. N√©cessite une surveillance continue de la performance de l'invite.
        Pour [`plandev-engineer`](.roo/rules/rules-plandev-engineer/plandev-engineer-reference.md#version-avanc√©e-du-prompt), cela souligne la n√©cessit√© de "surveillance automatis√©e du pipeline" et de "raffinement continu" pour d√©tecter et corriger toute d√©rive dans la g√©n√©ration des roadmaps due aux mises √† jour des mod√®les sous-jacents.

*   **Biais, St√©r√©otypes et Culture**
    Les LLM doivent √™tre √©quitables envers tous les utilisateurs, sans perp√©tuer de biais, de st√©r√©otypes ou de pr√©judices culturels. Le r√©f√©rentiel [`plandev-engineer`](.roo/rules/rules-plandev-engineer/plandev-engineer-reference.md#version-avanc√©e-du-prompt) inclut la "gestion des risques IA, drift, sycophancy, biais".

    *   **Vanilla Prompting**: Consiste simplement en une instruction dans l'invite disant au LLM d'√™tre impartial. √âgalement appel√© "correction morale auto-dirig√©e".
    *   **S√©lection d'Exemples √âquilibr√©s**: La s√©lection d'exemples √©quilibr√©s peut r√©duire les biais dans les sorties des LLM.
    *   **Conscience Culturelle (Cultural Awareness)**: Peut √™tre inject√©e dans les invites pour aider les LLM √† s'adapter culturellement. Cela peut se faire en demandant au LLM de raffiner sa propre sortie et de lui donner des instructions d'utiliser des mots culturellement pertinents.
    *   **AttrPrompt**: Une technique de prompting con√ßue pour √©viter de produire du texte biais√© vers certains attributs lors de la g√©n√©ration de donn√©es synth√©tiques. Demande au LLM de g√©n√©rer des attributs sp√©cifiques importants pour la diversit√© (par exemple, la localisation), puis le mod√®le g√©n√®re des donn√©es synth√©tiques en variant chacun de ces attributs.

*   **Ambigu√Øt√©**
    Les questions ambigu√´s peuvent √™tre interpr√©t√©es de plusieurs mani√®res, chaque interpr√©tation pouvant entra√Æner une r√©ponse diff√©rente. Le prompt [`plandev-engineer`](.roo/rules/rules-plandev-engineer/plandev-engineer-reference.md#version-avanc√©e-du-prompt) insiste sur l'**"analyse syst√©matique, clarification & gestion de l‚Äôambigu√Øt√©"**.

    *   **D√©monstrations Ambig√ºes**: Inclure des exemples avec un ensemble de labels ambigu peut am√©liorer les performances de l'ICL.
    *   **Clarification de Questions**: Permet au LLM d'identifier les questions ambigu√´s et de g√©n√©rer des questions de clarification √† poser √† l'utilisateur. Une fois clarifi√©es, le LLM peut r√©g√©n√©rer sa r√©ponse. Cela peut impliquer un pipeline o√π le LLM g√©n√®re une r√©ponse initiale, classe si des questions de clarification sont n√©cessaires, d√©cide quelles questions poser, puis g√©n√®re une r√©ponse finale.
        Cette approche est directement applicable √† la phase d'analyse du mode [`plandev-engineer`](.roo/rules/rules-plandev-engineer/plandev-engineer-reference.md#version-avanc√©e-du-prompt) o√π le mod√®le doit "formuler une question de clarification structur√©e" si un point est flou.

> **üõ†Ô∏è Adaptation Roo-Code par mode¬†:**
>
> - **plandev-engineer**¬†: L‚Äôalignement, la gestion des biais et la clarification sont obligatoires dans chaque phase (voir [Risques & mitigation](.roo/rules/rules-plandev-engineer/plandev-engineer-reference.md#version-avanc√©e-du-prompt)).
> - **orchestrator**¬†: Surveiller la d√©rive de prompt et la coh√©rence des r√©sultats lors de l‚Äôagr√©gation multi-modes ([rules-orchestration.md](.roo/rules/rules-orchestration.md)).
> - **debug**¬†: Documenter explicitement les ambigu√Øt√©s et biais d√©tect√©s lors du diagnostic ([rules-debug.md](.roo/rules/rules-debug.md)).
> - **documentation-writer**¬†: Privil√©gier la neutralit√©, la diversit√© des exemples et la clarification syst√©matique dans les guides ([rules-documentation.md](.roo/rules/rules-documentation.md)).

---


### 1. Ing√©nierie de Prompt et ses Composants D√©taill√©s

L'ing√©nierie de prompt est un processus it√©ratif essentiel pour d√©velopper un prompt en modifiant ou en changeant la technique de prompting utilis√©e.

*   **Composants fondamentaux d'un prompt**:
    *   **Directive** : L'instruction ou la question principale qui d√©finit l'intention du prompt (par exemple, "Donne-moi cinq bons livres √† lire."). Les directives peuvent √™tre explicites ou implicites.
    *   **Exemples (Exemplars ou Shots)** : Des d√©monstrations qui guident le GenAI dans l'ex√©cution d'une t√¢che. Cela inclut le "One-Shot" (un exemple) ou le "Few-Shot" (quelques exemples).
    *   **Format de sortie** : Sp√©cifier la structure de la r√©ponse souhait√©e (par exemple, CSV, Markdown, XML). Les **instructions de style** sont un type de formatage de sortie utilis√© pour modifier stylistiquement la sortie (par exemple, "√âcris un paragraphe clair et concis sur les lamas.").
    *   **R√¥le (Persona)** : Attribuer un r√¥le sp√©cifique au GenAI dans le prompt (par exemple, "Fais comme si tu √©tais un berger...") peut am√©liorer le style et la qualit√© de la sortie. Ce point est **crucial pour "vsix RooCode"** comme d√©taill√© ci-dessous.
    *   **Informations additionnelles (Contexte)** : Inclure des donn√©es suppl√©mentaires n√©cessaires √† la t√¢che. Le terme "contexte" est parfois ambigu, il est donc pr√©f√©rable de parler d'informations additionnelles.

### 2. Diversit√© Linguistique et Utilisation des Personas

Les LLMs actuels peuvent montrer une performance "cassante" (brittle performance) face √† des styles d'√©criture non standard, et les variations de style et de formatage des prompts ont un impact significatif sur la performance du LLM, m√™me pour un contenu s√©mantique identique.

*   **Impact de la diversit√© stylistique** :
    *   Les benchmarks actuels manquent de diversit√© de styles d'√©criture, se concentrant souvent sur des conventions standardis√©es, ce qui peut rendre les LLMs peu performants face √† des entr√©es "non standard".
    *   M√™me avec un contenu s√©mantique identique, les variations de style d'√©criture et de formatage de prompt **impactent significativement la performance** estim√©e du LLM.
    *   Certains styles d'√©criture (par exemple, des personas ayant un niveau d'√©ducation "inf√©rieur au lyc√©e" ou des personas "√¢g√©es") entra√Ænent **syst√©matiquement une baisse de performance** pour la majorit√© des mod√®les, ind√©pendamment de leur famille, taille ou date de publication.
    *   Les personas les plus performantes ont tendance √† utiliser un **langage plus acad√©mique et technique**, avec une meilleure lisibilit√© Flesch et des structures de phrase plus complexes.
    *   L'int√©gration d'attributs sociod√©mographiques (langue maternelle, niveau d'√©ducation, √¢ge, identit√© de genre/sexuelle) dans les personas peut g√©n√©rer **plus de variation de performance** que l'utilisation de personas de base diff√©rentes.
*   **Implications pour "vsix RooCode"** :
    *   Il est essentiel de tester la robustesse du syst√®me "vsix RooCode" face √† une **vari√©t√© de styles d'interaction utilisateur** et potentiellement d'int√©grer des m√©canismes pour adapter les prompts ou les r√©ponses en fonction du style d√©tect√©.
    *   Les lacunes des benchmarks existants en termes de diversit√© linguistique signifient que "vsix RooCode" ne devrait pas se fier uniquement aux scores de performance standards pour la s√©lection des mod√®les, mais aussi consid√©rer la **population d'utilisateurs cible**.
    *   L'instabilit√© du classement des mod√®les due aux variations de style d'√©criture est un point critique, car des changements minimes (par exemple, 5 points de pourcentage) peuvent **alt√©rer consid√©rablement le classement** d'un mod√®le.

### 3. Techniques de Prompting Avanc√©es

*   **In-Context Learning (ICL)** : Capacit√© des GenAIs √† apprendre des comp√©tences √† partir d'exemples ou d'instructions fournis dans le prompt, **sans mise √† jour des poids du mod√®le**. La quantit√©, l'ordre, la distribution et la qualit√© des exemples influencent la performance. La s√©lection d'exemples similaires √† l'instance de test est g√©n√©ralement b√©n√©fique.
*   **G√©n√©ration de Pens√©es (Thought Generation)** : Incite le LLM √† articuler son raisonnement avant de donner une r√©ponse finale, comme le **"Chain-of-Thought (CoT) Prompting"**. Des variantes comme "Zero-Shot CoT" (avec des phrases comme "R√©fl√©chissons √©tape par √©tape.") et "Few-Shot CoT" (avec des exemples incluant des cha√Ænes de pens√©e) existent.
*   **D√©composition** : D√©composer des probl√®mes complexes en sous-questions plus simples, par exemple avec le "Least-to-Most Prompting" ou "Tree-of-Thought".
*   **Ensembling** : Utiliser plusieurs prompts pour r√©soudre le m√™me probl√®me et agr√©ger les r√©ponses pour une sortie finale plus robuste (souvent par vote majoritaire, "Self-Consistency").
*   **Auto-critique (Self-Criticism)** : Demander aux LLMs de critiquer leurs propres sorties pour am√©liorer la qualit√© de la r√©ponse ("Self-Refine", "Chain-of-Verification").

### 4. Processus d'Ing√©nierie de Prompt et d'Answer Engineering

*   **Processus it√©ratif** : L'ing√©nierie de prompt est un processus it√©ratif qui implique l'inf√©rence sur un ensemble de donn√©es, l'√©valuation de la performance et la modification du template de prompt.
*   **Ing√©nierie de R√©ponse (Answer Engineering)** : Se concentre sur l'extraction de la r√©ponse finale √† partir de la sortie du LLM, en d√©finissant la **forme** (par exemple, un jeton, une √©tendue de jetons), l'**espace** (le domaine des valeurs) et un **extracteur** (par exemple, une expression r√©guli√®re ou un LLM s√©par√©). Ceci est crucial lorsque le contr√¥le total de l'espace de r√©ponse est impossible.

### 5. Aspects Multilingues et Multimodaux

*   Les GenAIs sont souvent principalement entra√Æn√©s avec des **donn√©es en anglais**, ce qui entra√Æne une disparit√© de qualit√© dans d'autres langues.
*   Des techniques multilingues sp√©cifiques ont √©merg√©, comme le "Translate First Prompting" ou des extensions de CoT et ICL pour des contextes multilingues.
*   La **s√©lection de la langue du template de prompt** peut influencer la performance du mod√®le, l'anglais √©tant souvent plus efficace en raison de la pr√©dominance des donn√©es d'entra√Ænement.
*   Les mod√®les GenAI √©voluent au-del√† du texte, n√©cessitant des techniques de prompting multimodales pour les images, l'audio, la vid√©o et la 3D.

### 6. Extensions du Prompting : Les Agents

*   Les LLMs peuvent √™tre dot√©s d'un acc√®s √† des **outils externes** (calculatrice, interpr√©teur de code, recherche Internet) pour surmonter leurs lacunes, transformant ainsi la prompt en un moteur d'agent.
*   Des exemples incluent les agents d'utilisation d'outils (comme MRKL System), les agents de g√©n√©ration de code (PAL, ToRA), les agents bas√©s sur l'observation (ReAct, Reflexion), et les syst√®mes de **Retrieval Augmented Generation (RAG)**, qui r√©cup√®rent des informations d'une source externe et les ins√®rent dans le prompt. Pour "vsix RooCode", l'int√©gration d'outils (comme un interpr√©teur de code ou un acc√®s √† une base de code externe) est essentielle.

### 7. Probl√®mes de Prompting (S√©curit√© et Alignement)

*   **S√©curit√©**:
    *   **Prompt Hacking** (injection de prompt, jailbreaking).
    *   **Risques de fuite de donn√©es** d'entra√Ænement ou de prompt.
    *   **Pr√©occupations li√©es √† la g√©n√©ration de code** (hallucination de paquets, bugs).
    *   **Mesures de durcissement** : Les d√©fenses bas√©es sur les prompts, les d√©tecteurs et les "Guardrails" (garde-fous) peuvent aider √† att√©nuer ces risques, bien qu'ils ne soient pas toujours enti√®rement s√©curis√©s. "vsix RooCode" doit int√©grer ces mesures pour garantir la s√©curit√© du code g√©n√©r√©.
*   **Alignement**:
    *   **Sensibilit√© aux prompts** : De petits changements (espaces, majuscules, d√©limiteurs) peuvent avoir un impact significatif sur la performance.
    *   **D√©rive du prompt (Prompt Drift)** : Le comportement des mod√®les peut changer avec le temps, n√©cessitant une surveillance continue de la performance des prompts.
    *   **Surconfiance et Calibrage** : Les LLMs peuvent √™tre trop confiants, ce qui peut entra√Æner une sur-d√©pendance de l'utilisateur.
    *   **Biais, St√©r√©otypes et Culture** : Les LLMs peuvent perp√©tuer des biais (par exemple, culturels ou de st√©r√©otypes) dans leurs sorties. L'utilisation de **personas** dans l'√©valuation (comme vu dans le nouveau document) met en √©vidence cette sensibilit√©.
    *   **Ambigu√Øt√©** : Les questions ambigu√´s peuvent √™tre interpr√©t√©es de plusieurs fa√ßons, ce qui repr√©sente un d√©fi pour les mod√®les.

### 8. √âvaluation des R√©ponses de l'LLM

*   Il est crucial de savoir comment √©valuer les sorties des agents et des techniques de prompting pour garantir l'exactitude et √©viter les hallucinations.
*   Les LLMs peuvent √™tre utilis√©s comme √©valuateurs eux-m√™mes, en b√©n√©ficiant de techniques comme l'ICL, le CoT ou l'√©valuation bas√©e sur les r√¥les.
*   Le **format de sortie** (√©chelle lin√©aire, binaire, Likert) peut affecter significativement la performance de l'√©valuation.

En r√©sum√©, pour "vsix RooCode", au-del√† des composants de base du prompting, il est imp√©ratif de se concentrer sur la **robustesse du syst√®me face √† la diversit√© des styles d'√©criture des utilisateurs (via l'√©tude des personas)**, l'int√©gration intelligente d'outils externes pour les capacit√©s d'agent, et la mise en place de **mesures de s√©curit√© et d'alignement rigoureuses**. L'it√©ration constante et l'√©valuation m√©ticuleuse des prompts et des r√©ponses sont la cl√© pour un syst√®me fiable et performant.