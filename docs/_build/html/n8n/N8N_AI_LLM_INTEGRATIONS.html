

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Intégrations IA &amp; LLM dans n8n &mdash; EMAIL_SENDER_1 1.0.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/graphviz.css?v=4ae1632d" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=8d563738"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            EMAIL_SENDER_1
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contenu:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api/index.html">Documentation des API</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">EMAIL_SENDER_1</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Intégrations IA &amp; LLM dans n8n</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/n8n/N8N_AI_LLM_INTEGRATIONS.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="integrations-ia-llm-dans-n8n">
<h1>Intégrations IA &amp; LLM dans n8n<a class="headerlink" href="#integrations-ia-llm-dans-n8n" title="Link to this heading"></a></h1>
<p>Ce document détaille les différentes façons d’intégrer des modèles de langage (LLM) et des fonctionnalités d’IA dans vos workflows n8n.</p>
<section id="modele-de-chat-openai-gpt-3-5-gpt-4">
<h2>Modèle de Chat OpenAI (GPT-3.5/GPT-4)<a class="headerlink" href="#modele-de-chat-openai-gpt-3-5-gpt-4" title="Link to this heading"></a></h2>
<p>Utilise l’API Chat d’OpenAI pour générer des réponses. Vous spécifiez le modèle, les prompts et les paramètres comme la température.</p>
<p>Ce nœud peut prendre un prompt système et un prompt utilisateur pour générer une complétion. Par exemple, pour utiliser le modèle GPT-3.5 Turbo avec un rôle système et un message utilisateur :</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;ChatGPT&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;n8n-nodes-langchain.lmChatOpenAi&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;typeVersion&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;parameters&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;model&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;temperature&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.7</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;maxTokens&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">500</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;systemPrompt&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;You are a helpful assistant.&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;userPrompt&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Hello! How can I automate tasks with n8n?&quot;</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="nt">&quot;credentials&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;openAiApi&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;YOUR_CRED_ID&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;OpenAI API&quot;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p><strong>Explication :</strong> Cette configuration définit le nœud Chat OpenAI pour utiliser le modèle GPT-3.5 avec un message système fournissant le contexte et un message utilisateur. La réponse sera disponible en tant que sortie du nœud. Assurez-vous d’avoir configuré des identifiants API OpenAI nommés “OpenAI API”, référencés dans les credentials. Vous pouvez ajuster la température pour le caractère aléatoire et maxTokens pour la longueur.</p>
</section>
<section id="completion-de-texte-openai">
<h2>Complétion de Texte OpenAI<a class="headerlink" href="#completion-de-texte-openai" title="Link to this heading"></a></h2>
<p>Pour les modèles de complétion de texte GPT-3 (comme text-davinci-003), vous pouvez utiliser le nœud OpenAI en mode complétion. Fournissez un prompt et des paramètres. Par exemple :</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;OpenAI Completion&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;n8n-nodes-langchain.openai&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;typeVersion&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;parameters&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;model&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;text-davinci-003&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;prompt&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Summarize the following text: {{$json[\&quot;content\&quot;]}}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;temperature&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.5</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;maxTokens&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">200</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="nt">&quot;credentials&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;openAiApi&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;OpenAI API&quot;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p><strong>Explication :</strong> Cela enverra un prompt au point de terminaison de complétion d’OpenAI pour résumer un contenu provenant des données d’entrée. La syntaxe <code class="docutils literal notranslate"><span class="pre">{{$json[&quot;content&quot;]}}</span></code> insère des données du nœud précédent. Le nœud utilise les identifiants API OpenAI. La sortie apparaît dans le JSON du nœud (champ result contenant le texte de complétion).</p>
</section>
<section id="agents-ia-avec-outils">
<h2>Agents IA (avec Outils)<a class="headerlink" href="#agents-ia-avec-outils" title="Link to this heading"></a></h2>
<p>n8n prend en charge des nœuds Agent avancés qui permettent à un modèle d’IA d’utiliser des outils (comme la recherche web, des calculatrices ou d’autres fonctions de nœud) pour accomplir des tâches. Par exemple, l’Agent de Fonctions OpenAI peut appeler des fonctions personnalisées, et l’Agent ReAct utilise la stratégie ReAct pour décider quel outil utiliser à chaque étape.</p>
<p>Voici un exemple simplifié de configuration de nœud Agent IA utilisant un modèle OpenAI et un outil (par exemple, un outil de recherche Google) :</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;AI Agent (ReAct)&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;n8n-nodes-langchain.agent&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;typeVersion&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;parameters&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;agentType&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;react&quot;</span><span class="p">,</span><span class="w"> </span><span class="c1">// Type d&#39;agent : &quot;react&quot;, &quot;functions&quot;, &quot;planAndExecute&quot;, etc.</span>
<span class="w">    </span><span class="nt">&quot;model&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;gpt-4&quot;</span><span class="p">,</span><span class="w"> </span><span class="c1">// Modèle LLM sous-jacent</span>
<span class="w">    </span><span class="nt">&quot;memory&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="p">,</span><span class="w"> </span><span class="c1">// Utiliser ou non la mémoire conversationnelle</span>
<span class="w">    </span><span class="nt">&quot;tools&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">      </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;googleSearch&quot;</span><span class="p">,</span><span class="w"> </span><span class="c1">// Nom d&#39;un nœud outil connecté</span>
<span class="w">        </span><span class="nt">&quot;input&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;What is n8n?&quot;</span><span class="w"> </span><span class="c1">// Exemple de requête pour laquelle l&#39;agent utilisera cet outil</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">    </span><span class="p">]</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p><strong>Explication :</strong> Cet agent est configuré pour utiliser la stratégie ReAct avec GPT-4. Le tableau tools correspondrait à des nœuds Outil réels connectés au nœud Agent (par exemple, un nœud Google Search dans le workflow). En pratique, vous ajoutez des outils via l’interface utilisateur de l’éditeur (ils deviennent des sous-nœuds). L’agent décidera quand utiliser l’outil. Par exemple, il pourrait utiliser l’outil Google Search pour récupérer des informations nécessaires pour répondre à une question.</p>
<p><strong>Note :</strong> Le cluster de nœuds agent gère la logique ; assurez-vous d’avoir configuré les nœuds d’outils appropriés et les identifiants (comme les clés API Google). Les agents peuvent également utiliser d’autres modes comme l’Agent de Fonctions OpenAI, l’Agent Plan-and-Execute, ou l’Agent SQL, chacun permettant à l’IA d’effectuer des tâches complexes spécifiques (par exemple, appeler des fonctions définies, décomposer une tâche en sous-tâches, ou exécuter des requêtes SQL via des identifiants de base de données fournis).</p>
</section>
<section id="embeddings-et-bases-de-donnees-vectorielles">
<h2>Embeddings et Bases de Données Vectorielles<a class="headerlink" href="#embeddings-et-bases-de-donnees-vectorielles" title="Link to this heading"></a></h2>
<p>n8n fournit des nœuds pour générer des embeddings de texte avec des modèles (OpenAI, Cohere, Google PaLM, etc.) et pour les stocker/récupérer dans des bases de données vectorielles (Pinecone, Weaviate, etc.).</p>
<p>Par exemple, le nœud Embeddings OpenAI peut prendre du texte et retourner un vecteur. L’utilisation est simple : vous spécifiez le champ de texte à transformer en embedding et le modèle. La sortie est généralement un tableau de nombres représentant le vecteur. Ceux-ci peuvent être utilisés avec un nœud Vector Store (comme Pinecone) pour ajouter ou interroger des vecteurs.</p>
<p>Exemple pour un nœud Embedding OpenAI :</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Text to Vector&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;n8n-nodes-langchain.embeddingsOpenAi&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;typeVersion&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;parameters&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;model&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;text-embedding-ada-002&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;text&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;={{ $json[\&quot;content\&quot;] }}&quot;</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="nt">&quot;credentials&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;openAiApi&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;OpenAI API&quot;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p><strong>Explication :</strong> Cela prend le champ content du JSON d’entrée et génère un embedding de 1536 dimensions en utilisant le modèle ada d’OpenAI. Vous enverriez généralement ce vecteur à un stockage ou l’utiliseriez dans une recherche de similarité.</p>
<p>Pour le stockage, un nœud Pinecone (ou autre base de données vectorielle) peut être utilisé, avec des opérations comme Insert Vector ou Query Vector (vous fournissez le nom de l’index, les données vectorielles, et toutes les métadonnées ou vecteurs de requête nécessaires).</p>
<p>Comme l’utilisation des bases de données vectorielles peut être complexe, référez-vous à la documentation spécifique des nœuds pour les noms exacts des paramètres.</p>
<p>Le concept clé est que les nœuds Embeddings convertissent le texte en vecteurs numériques, et les nœuds Vector Store permettent de sauvegarder et de rechercher ces vecteurs, permettant des workflows comme la recherche sémantique ou la génération augmentée par récupération.</p>
</section>
<section id="integration-avec-d-autres-modeles">
<h2>Intégration avec d’autres modèles<a class="headerlink" href="#integration-avec-d-autres-modeles" title="Link to this heading"></a></h2>
<p>En plus d’OpenAI, n8n prend en charge d’autres fournisseurs de LLM comme :</p>
<ul class="simple">
<li><p><strong>Anthropic Claude</strong> : Pour des modèles comme Claude 2 ou Claude Instant</p></li>
<li><p><strong>Google PaLM/Gemini</strong> : Pour les modèles de Google</p></li>
<li><p><strong>Cohere</strong> : Pour la génération de texte et les embeddings</p></li>
<li><p><strong>Hugging Face</strong> : Pour accéder à des milliers de modèles open source</p></li>
</ul>
<p>La configuration est similaire à celle d’OpenAI, mais avec des paramètres spécifiques au fournisseur et des identifiants d’API différents.</p>
</section>
<section id="cas-d-utilisation-courants">
<h2>Cas d’utilisation courants<a class="headerlink" href="#cas-d-utilisation-courants" title="Link to this heading"></a></h2>
<ol class="simple">
<li><p><strong>Génération de contenu</strong> : Utiliser des LLM pour créer des textes, résumés, ou traductions</p></li>
<li><p><strong>Analyse de sentiment</strong> : Classifier le ton ou l’intention d’un texte</p></li>
<li><p><strong>Extraction d’informations</strong> : Extraire des données structurées à partir de texte non structuré</p></li>
<li><p><strong>Recherche sémantique</strong> : Trouver des documents similaires basés sur le sens plutôt que sur des mots-clés</p></li>
<li><p><strong>Chatbots</strong> : Créer des assistants conversationnels avec mémoire et accès à des outils externes</p></li>
<li><p><strong>Classification de documents</strong> : Catégoriser automatiquement des textes</p></li>
</ol>
</section>
<section id="bonnes-pratiques">
<h2>Bonnes pratiques<a class="headerlink" href="#bonnes-pratiques" title="Link to this heading"></a></h2>
<ul class="simple">
<li><p><strong>Gestion des tokens</strong> : Surveillez l’utilisation des tokens pour contrôler les coûts</p></li>
<li><p><strong>Prompts efficaces</strong> : Concevez des prompts clairs et spécifiques pour obtenir les meilleurs résultats</p></li>
<li><p><strong>Validation des sorties</strong> : Vérifiez et nettoyez les sorties des LLM avant de les utiliser dans des étapes critiques</p></li>
<li><p><strong>Mise en cache</strong> : Envisagez de mettre en cache les résultats pour les requêtes fréquentes</p></li>
<li><p><strong>Sécurité</strong> : Soyez prudent avec les données sensibles envoyées aux API externes</p></li>
<li><p><strong>Fallbacks</strong> : Prévoyez des alternatives en cas d’échec d’un appel API</p></li>
</ul>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, EMAIL_SENDER_1 Team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>