// Package advanced_autonomy_manager implements the 21st manager in the FMOUA Framework
// providing complete autonomy for maintenance and organization across all 20 previous managers
package main

import (
	"context"
	"fmt"
	"sync"
	"time"

	interfaces "email_sender/development/managers/advanced-autonomy-manager/interfaces"
	"email_sender/development/managers/advanced-autonomy-manager/internal/coordination"
	"email_sender/development/managers/advanced-autonomy-manager/internal/decision"
	"email_sender/development/managers/advanced-autonomy-manager/internal/discovery"
	"email_sender/development/managers/advanced-autonomy-manager/internal/healing"
	"email_sender/development/managers/advanced-autonomy-manager/internal/monitoring"
	"email_sender/development/managers/advanced-autonomy-manager/internal/predictive"
)

// AdvancedAutonomyManagerImpl est l'implémentation complète du 21ème manager FMOUA
// Il fournit une autonomie complète pour la maintenance et l'organisation de l'écosystème
type AdvancedAutonomyManagerImpl struct {
	// Configuration de base
	config      *AutonomyConfig
	logger      interfaces.Logger
	version     string
	name        string
	initialized bool
	// Composants principaux (5 core components)
	decisionEngine      *decision.AutonomousDecisionEngine
	predictiveCore      *predictive.PredictiveMaintenanceCore
	monitoringDashboard *monitoring.RealTimeMonitoringDashboard
	healingSystem       *healing.NeuralAutoHealingSystem
	coordinationLayer   *coordination.MasterCoordinationLayer

	// État du système
	systemState      *interfaces.SystemSituation
	managerStates    map[string]*interfaces.ManagerState
	activeOperations map[string]*interfaces.Operation

	// Synchronisation
	mutex          sync.RWMutex
	operationMutex sync.Mutex
	ctx            context.Context
	cancel         context.CancelFunc
	// Connexions aux 20 managers précédents
	managerConnections map[string]interfaces.BaseManager
	discoveryService   *discovery.ManagerDiscoveryService

	// Métriques et surveillance
	metrics         *EcosystemMetrics
	healthTracker   *HealthTracker
	performanceData *PerformanceData
}

// AutonomyConfig contient la configuration complète du manager autonome
type AutonomyConfig struct {
	// Niveau d'autonomie
	AutonomyLevel interfaces.AutonomyLevel `yaml:"autonomy_level" json:"autonomy_level"`
	// Configuration des composants
	DecisionConfig     *interfaces.DecisionEngineConfig `yaml:"decision_config" json:"decision_config"`
	PredictiveConfig   *interfaces.PredictiveConfig     `yaml:"predictive_config" json:"predictive_config"`
	MonitoringConfig   *interfaces.MonitoringConfig     `yaml:"monitoring_config" json:"monitoring_config"`
	HealingConfig      *interfaces.HealingConfig        `yaml:"healing_config" json:"healing_config"`
	CoordinationConfig *interfaces.CoordinationConfig   `yaml:"coordination_config" json:"coordination_config"`
	DiscoveryConfig    *discovery.DiscoveryConfig       `yaml:"discovery_config" json:"discovery_config"`

	// Paramètres de performance
	MaxConcurrentOps    int           `yaml:"max_concurrent_ops" json:"max_concurrent_ops"`
	DecisionTimeout     time.Duration `yaml:"decision_timeout" json:"decision_timeout"`
	HealthCheckInterval time.Duration `yaml:"health_check_interval" json:"health_check_interval"`

	// Seuils et limites
	SafetyThreshold   float64 `yaml:"safety_threshold" json:"safety_threshold"`
	RiskTolerance     float64 `yaml:"risk_tolerance" json:"risk_tolerance"`
	PerformanceTarget float64 `yaml:"performance_target" json:"performance_target"`

	// Apprentissage et adaptation
	LearningEnabled  bool          `yaml:"learning_enabled" json:"learning_enabled"`
	AdaptationRate   float64       `yaml:"adaptation_rate" json:"adaptation_rate"`
	HistoryRetention time.Duration `yaml:"history_retention" json:"history_retention"`
}

// NewAdvancedAutonomyManager crée une nouvelle instance complète du 21ème manager
func NewAdvancedAutonomyManager(config *AutonomyConfig, logger interfaces.Logger) (*AdvancedAutonomyManagerImpl, error) {
	if config == nil {
		return nil, fmt.Errorf("configuration is required")
	}

	if logger == nil {
		return nil, fmt.Errorf("logger is required")
	}
	ctx, cancel := context.WithCancel(context.Background())

	// Initialiser le service de découverte des managers
	discoveryService, err := discovery.NewManagerDiscoveryService(config.DiscoveryConfig, logger)
	if err != nil {
		return nil, fmt.Errorf("failed to create discovery service: %w", err)
	}

	manager := &AdvancedAutonomyManagerImpl{
		config:             config,
		logger:             logger,
		version:            "1.0.0",
		name:               "AdvancedAutonomyManager",
		initialized:        false,
		systemState:        &interfaces.SystemSituation{},
		managerStates:      make(map[string]*interfaces.ManagerState),
		activeOperations:   make(map[string]*interfaces.Operation),
		managerConnections: make(map[string]interfaces.BaseManager),
		discoveryService:   discoveryService,
		ctx:                ctx,
		cancel:             cancel,
		metrics:            NewEcosystemMetrics(),
		healthTracker:      NewHealthTracker(),
		performanceData:    NewPerformanceData(),
	}

	return manager, nil
}

// Initialize initialise tous les composants du manager autonome
func (am *AdvancedAutonomyManagerImpl) Initialize(ctx context.Context) error {
	am.mutex.Lock()
	defer am.mutex.Unlock()

	if am.initialized {
		return fmt.Errorf("manager already initialized")
	}

	am.logger.Info("Initializing AdvancedAutonomyManager - 21st manager in FMOUA ecosystem")

	// 1. Initialiser le moteur de décision autonome (composant 1/5)
	decisionEngine, err := decision.NewAutonomousDecisionEngine(am.config.DecisionConfig, am.logger)
	if err != nil {
		return fmt.Errorf("failed to initialize decision engine: %w", err)
	}
	am.decisionEngine = decisionEngine

	// 2. Initialiser le core de maintenance prédictive (composant 2/5)
	predictiveCore, err := predictive.NewPredictiveMaintenanceCore(am.config.PredictiveConfig, am.logger)
	if err != nil {
		return fmt.Errorf("failed to initialize predictive core: %w", err)
	}
	am.predictiveCore = predictiveCore

	// 3. Initialiser le dashboard de monitoring temps réel (composant 3/5)
	monitoringDashboard, err := monitoring.NewRealTimeMonitoringDashboard(am.config.MonitoringConfig, am.logger)
	if err != nil {
		return fmt.Errorf("failed to initialize monitoring dashboard: %w", err)
	}
	am.monitoringDashboard = monitoringDashboard

	// 4. Initialiser le système neural d'auto-healing (composant 4/5)
	healingSystem, err := healing.NewNeuralAutoHealingSystem(am.config.HealingConfig, am.logger)
	if err != nil {
		return fmt.Errorf("failed to initialize healing system: %w", err)
	}
	am.healingSystem = healingSystem
	// 5. Initialiser la couche de coordination maître (composant 5/5)
	coordinationLayer, err := coordination.NewMasterCoordinationLayer(am.config.CoordinationConfig, am.logger)
	if err != nil {
		return fmt.Errorf("failed to initialize coordination layer: %w", err)
	}
	am.coordinationLayer = coordinationLayer

	// Connecter aux 20 managers précédents
	if err := am.connectToEcosystemManagers(ctx); err != nil {
		return fmt.Errorf("failed to connect to ecosystem managers: %w", err)
	}

	// Démarrer les processus de surveillance et de coordination
	go am.startEcosystemMonitoring(ctx)
	go am.startAutonomousOperations(ctx)
	go am.startHealthTracking(ctx)

	am.initialized = true
	am.logger.Info("AdvancedAutonomyManager successfully initialized with complete autonomy capabilities")

	return nil
}

// HealthCheck vérifie la santé de tous les composants et de l'écosystème
func (am *AdvancedAutonomyManagerImpl) HealthCheck(ctx context.Context) error {
	am.mutex.RLock()
	defer am.mutex.RUnlock()

	if !am.initialized {
		return fmt.Errorf("manager not initialized")
	}

	// Vérifier tous les composants principaux
	checks := []struct {
		name  string
		check func(context.Context) error
	}{
		{"DecisionEngine", am.decisionEngine.HealthCheck},
		{"PredictiveCore", am.predictiveCore.HealthCheck},
		{"MonitoringDashboard", am.monitoringDashboard.HealthCheck},
		{"HealingSystem", am.healingSystem.HealthCheck},
		{"CoordinationLayer", am.coordinationLayer.HealthCheck},
	}

	for _, check := range checks {
		if err := check.check(ctx); err != nil {
			return fmt.Errorf("%s health check failed: %w", check.name, err)
		}
	}

	// Vérifier la santé de l'écosystème complet
	ecosystemHealth, err := am.MonitorEcosystemHealth(ctx)
	if err != nil {
		return fmt.Errorf("ecosystem health check failed: %w", err)
	}

	if ecosystemHealth.OverallHealth < am.config.SafetyThreshold {
		return fmt.Errorf("ecosystem health below safety threshold: %.2f < %.2f",
			ecosystemHealth.OverallHealth, am.config.SafetyThreshold)
	}

	return nil
}

// Cleanup nettoie toutes les ressources et arrête le manager
func (am *AdvancedAutonomyManagerImpl) Cleanup() error {
	am.mutex.Lock()
	defer am.mutex.Unlock()

	am.logger.Info("Starting AdvancedAutonomyManager cleanup")

	// Annuler le contexte pour arrêter tous les processus
	if am.cancel != nil {
		am.cancel()
	}

	// Nettoyer tous les composants dans l'ordre inverse d'initialisation
	var errors []error

	if am.coordinationLayer != nil {
		if err := am.coordinationLayer.Cleanup(); err != nil {
			errors = append(errors, fmt.Errorf("coordination layer cleanup failed: %w", err))
		}
	}

	if am.healingSystem != nil {
		if err := am.healingSystem.Cleanup(); err != nil {
			errors = append(errors, fmt.Errorf("healing system cleanup failed: %w", err))
		}
	}

	if am.monitoringDashboard != nil {
		if err := am.monitoringDashboard.Cleanup(); err != nil {
			errors = append(errors, fmt.Errorf("monitoring dashboard cleanup failed: %w", err))
		}
	}

	if am.predictiveCore != nil {
		if err := am.predictiveCore.Cleanup(); err != nil {
			errors = append(errors, fmt.Errorf("predictive core cleanup failed: %w", err))
		}
	}
	if am.decisionEngine != nil {
		if err := am.decisionEngine.Cleanup(); err != nil {
			errors = append(errors, fmt.Errorf("decision engine cleanup failed: %w", err))
		}
	}

	if am.discoveryService != nil {
		if err := am.discoveryService.Cleanup(); err != nil {
			errors = append(errors, fmt.Errorf("discovery service cleanup failed: %w", err))
		}
	}

	am.initialized = false

	if len(errors) > 0 {
		return fmt.Errorf("cleanup completed with errors: %v", errors)
	}

	am.logger.Info("AdvancedAutonomyManager cleanup completed successfully")
	return nil
}

// OrchestrateAutonomousMaintenance coordonne une opération de maintenance complètement autonome
func (am *AdvancedAutonomyManagerImpl) OrchestrateAutonomousMaintenance(ctx context.Context) (*interfaces.AutonomyResult, error) {
	am.operationMutex.Lock()
	defer am.operationMutex.Unlock()

	am.logger.Info("Starting autonomous maintenance orchestration across 20 managers")

	// 1. Analyser l'état actuel de l'écosystème
	systemSituation, err := am.captureSystemSituation(ctx)
	if err != nil {
		return nil, fmt.Errorf("failed to capture system situation: %w", err)
	}

	// 2. Générer des décisions autonomes basées sur l'IA
	decisions, err := am.decisionEngine.GenerateMaintenanceDecisions(ctx, systemSituation)
	if err != nil {
		return nil, fmt.Errorf("failed to generate maintenance decisions: %w", err)
	}

	// 3. Évaluer les risques et filtrer les décisions sûres
	safeDecisions, err := am.decisionEngine.FilterSafeDecisions(ctx, decisions, am.config.RiskTolerance)
	if err != nil {
		return nil, fmt.Errorf("failed to filter safe decisions: %w", err)
	}

	// 4. Exécuter les décisions via la couche de coordination
	executionResults, err := am.coordinationLayer.ExecuteDecisionsAcrossManagers(ctx, safeDecisions)
	if err != nil {
		return nil, fmt.Errorf("failed to execute decisions: %w", err)
	}

	// 5. Surveiller l'exécution et appliquer l'auto-healing si nécessaire
	healingResults, err := am.healingSystem.MonitorAndHealExecution(ctx, executionResults)
	if err != nil {
		return nil, fmt.Errorf("failed during execution monitoring: %w", err)
	}

	// 6. Compiler les résultats finaux
	result := &interfaces.AutonomyResult{
		ID:        generateOperationID(),
		StartTime: time.Now(),
		// DecisionsGenerated: len(decisions), // Supprimé, sera calculé ou omis
		// DecisionsExecuted:  len(safeDecisions), // Supprimé, sera calculé ou omis
		AffectedComponents: extractAffectedManagers(safeDecisions),
		ExecutedActions:    executionResults,
		Issues:             healingResults,
		Success:            calculateOverallSuccess(executionResults),
		ImprovementMetrics: am.calculatePerformanceMetrics(ctx),
	}

	// 7. Apprendre des résultats pour les futures opérations
	if am.config.LearningEnabled {
		// am.decisionEngine.LearnFromResults(ctx, result) // Commenté pour l'instant
	}

	am.logger.Info("Autonomous maintenance orchestration completed successfully")
	return result, nil
}

// PredictMaintenanceNeeds prédit les besoins futurs de maintenance
func (am *AdvancedAutonomyManagerImpl) PredictMaintenanceNeeds(ctx context.Context, timeHorizon time.Duration) (*interfaces.PredictionResult, error) {
	am.logger.Info("Predicting maintenance needs with ML analysis")

	// Utiliser le core de maintenance prédictive
	forecast, err := am.predictiveCore.GenerateMaintenanceForecast(ctx, timeHorizon)
	if err != nil {
		return nil, fmt.Errorf("failed to generate maintenance forecast: %w", err)
	}

	// Enrichir avec des données de l'écosystème
	enrichedForecast, err := am.enrichForecastWithEcosystemData(ctx, forecast)
	if err != nil {
		return nil, fmt.Errorf("failed to enrich forecast: %w", err)
	}

	result := &interfaces.PredictionResult{
		GeneratedAt:     time.Now(),
		TimeHorizon:     timeHorizon,
		Forecast:        enrichedForecast,
		Confidence:      am.calculatePredictionConfidence(enrichedForecast),
		Recommendations: am.generateMaintenanceRecommendations(enrichedForecast),
	}

	return result, nil
}

// ExecuteAutonomousDecisions exécute un ensemble de décisions autonomes
func (am *AdvancedAutonomyManagerImpl) ExecuteAutonomousDecisions(ctx context.Context, decisions []interfaces.AutonomousDecision) error {
	am.logger.Info(fmt.Sprintf("Executing %d autonomous decisions", len(decisions)))

	// Valider toutes les décisions avant l'exécution
	for _, decision := range decisions {
		if err := am.decisionEngine.ValidateDecision(ctx, &decision); err != nil {
			return fmt.Errorf("decision validation failed for %s: %w", decision.ID, err)
		}
	}

	// Exécuter via la couche de coordination avec monitoring
	return am.coordinationLayer.ExecuteDecisionsWithMonitoring(ctx, decisions, am.monitoringDashboard)
}

// MonitorEcosystemHealth surveille la santé complète de l'écosystème
func (am *AdvancedAutonomyManagerImpl) MonitorEcosystemHealth(ctx context.Context) (*interfaces.EcosystemHealth, error) {
	return am.monitoringDashboard.GenerateEcosystemHealthReport(ctx, am.managerConnections)
}

// Méthodes internes pour supporter l'implémentation
func (am *AdvancedAutonomyManagerImpl) connectToEcosystemManagers(ctx context.Context) error {
	am.logger.Info("Starting discovery and connection to 20 ecosystem managers")

	// Initialiser le service de découverte
	if err := am.discoveryService.Initialize(ctx); err != nil {
		return fmt.Errorf("failed to initialize discovery service: %w", err)
	}

	// Découvrir tous les managers de l'écosystème
	discoveredManagers, err := am.discoveryService.DiscoverAllManagers(ctx)
	if err != nil {
		am.logger.WithError(err).Warn("Manager discovery completed with errors, continuing with discovered managers")
	}

	// Mettre à jour les connexions
	am.mutex.Lock()
	am.managerConnections = discoveredManagers
	am.mutex.Unlock()

	// Enregistrer les managers découverts dans la couche de coordination
	for name, manager := range discoveredManagers {
		if err := am.coordinationLayer.RegisterManager(name, manager); err != nil {
			am.logger.WithError(err).Warn(fmt.Sprintf("Failed to register manager %s in coordination layer", name))
		} else {
			am.logger.Info(fmt.Sprintf("Successfully registered manager: %s", name))
		}
	}

	// Démarrer la surveillance des connexions
	go am.discoveryService.MonitorConnections(ctx)

	am.logger.Info(fmt.Sprintf("Successfully connected to %d ecosystem managers", len(discoveredManagers)))
	return nil
}

func (am *AdvancedAutonomyManagerImpl) startEcosystemMonitoring(ctx context.Context) {
	ticker := time.NewTicker(am.config.HealthCheckInterval)
	defer ticker.Stop()

	for {
		select {
		case <-ctx.Done():
			return
		case <-ticker.C:
			if err := am.updateSystemState(ctx); err != nil {
				am.logger.WithError(err).Error("Failed to update system state")
			}
		}
	}
}

func (am *AdvancedAutonomyManagerImpl) startAutonomousOperations(ctx context.Context) {
	// Logique pour démarrer les opérations autonomes continues
	am.logger.Info("Starting autonomous operations monitoring")

	for {
		select {
		case <-ctx.Done():
			return
		default:
			// Vérifier s'il y a des opérations autonomes à déclencher
			if am.shouldTriggerAutonomousOperation(ctx) {
				go am.executeScheduledMaintenance(ctx)
			}
			time.Sleep(time.Minute) // Vérification toutes les minutes
		}
	}
}

func (am *AdvancedAutonomyManagerImpl) startHealthTracking(ctx context.Context) {
	// Surveillance continue de la santé
	ticker := time.NewTicker(30 * time.Second)
	defer ticker.Stop()

	for {
		select {
		case <-ctx.Done():
			return
		case <-ticker.C:
			am.healthTracker.UpdateHealthMetrics(ctx, am.managerConnections)
		}
	}
}

// Méthodes utilitaires
func (am *AdvancedAutonomyManagerImpl) captureSystemSituation(ctx context.Context) (*interfaces.SystemSituation, error) {
	// Capture l'état actuel de tous les managers
	situation := &interfaces.SystemSituation{
		Timestamp:     time.Now(),
		ManagerStates: make(map[string]*interfaces.ManagerState),
	}

	// Collecter l'état de chaque manager connecté
	for name, manager := range am.managerConnections {
		state, err := am.captureManagerState(ctx, name, manager)
		if err != nil {
			am.logger.WithError(err).Warn(fmt.Sprintf("Failed to capture state for manager %s", name))
			continue
		}
		situation.ManagerStates[name] = state
	}

	// Calculer la santé globale
	situation.OverallHealth = am.calculateOverallHealth(situation.ManagerStates)

	return situation, nil
}

func (am *AdvancedAutonomyManagerImpl) captureManagerState(ctx context.Context, name string, manager interfaces.BaseManager) (*interfaces.ManagerState, error) {
	state := &interfaces.ManagerState{
		Name:               name,
		LastHealthCheck:    time.Now(),
		Metrics:            make(map[string]interface{}),
		DependenciesStatus: make(map[string]bool),
	}

	// Effectuer un health check
	if err := manager.HealthCheck(ctx); err != nil {
		state.Status = "degraded"
		state.HealthScore = 0.5
		state.ErrorCount++
	} else {
		state.Status = "running"
		state.HealthScore = 1.0
	}

	return state, nil
}

func (am *AdvancedAutonomyManagerImpl) calculateOverallHealth(managerStates map[string]*interfaces.ManagerState) float64 {
	if len(managerStates) == 0 {
		return 0.0
	}

	totalHealth := 0.0
	for _, state := range managerStates {
		totalHealth += state.HealthScore
	}

	return totalHealth / float64(len(managerStates))
}

func (am *AdvancedAutonomyManagerImpl) updateSystemState(ctx context.Context) error {
	situation, err := am.captureSystemSituation(ctx)
	if err != nil {
		return err
	}

	am.mutex.Lock()
	am.systemState = situation
	am.mutex.Unlock()

	return nil
}

func (am *AdvancedAutonomyManagerImpl) shouldTriggerAutonomousOperation(ctx context.Context) bool {
	// Logique pour déterminer si une opération autonome doit être déclenchée
	am.mutex.RLock()
	defer am.mutex.RUnlock()

	// Vérifier la santé du système
	if am.systemState.OverallHealth < am.config.SafetyThreshold {
		return true
	}

	// Vérifier s'il y a des anomalies détectées
	if len(am.systemState.DetectedAnomalies) > 0 {
		return true
	}

	return false
}

func (am *AdvancedAutonomyManagerImpl) executeScheduledMaintenance(ctx context.Context) {
	result, err := am.OrchestrateAutonomousMaintenance(ctx)
	if err != nil {
		am.logger.WithError(err).Error("Scheduled autonomous maintenance failed")
		return
	}

	am.logger.Info(fmt.Sprintf("Scheduled maintenance completed: %+v", result))
}

// Fonctions utilitaires
func generateOperationID() string {
	return fmt.Sprintf("auto-op-%d", time.Now().UnixNano())
}

func extractAffectedManagers(decisions []interfaces.AutonomousDecision) []string {
	managerSet := make(map[string]bool)
	for _, decision := range decisions {
		for _, manager := range decision.TargetManagers {
			managerSet[manager] = true
		}
	}

	managers := make([]string, 0, len(managerSet))
	for manager := range managerSet {
		managers = append(managers, manager)
	}

	return managers
}

func calculateOverallSuccess(results map[string]interface{}) bool {
	// Logique pour calculer le succès global basé sur les résultats
	successCount := 0
	totalCount := 0

	for _, result := range results {
		totalCount++
		if success, ok := result.(bool); ok && success {
			successCount++
		}
	}

	return totalCount > 0 && float64(successCount)/float64(totalCount) >= 0.8
}

func (am *AdvancedAutonomyManagerImpl) calculatePerformanceMetrics(ctx context.Context) map[string]float64 {
	return map[string]float64{
		"response_time":         float64(am.performanceData.GetAverageResponseTime()),
		"throughput":            float64(am.performanceData.GetThroughput()),
		"success_rate":          am.performanceData.GetSuccessRate(),
		"resource_usage_cpu":    am.performanceData.GetResourceUsage()["cpu"],
		"resource_usage_memory": am.performanceData.GetResourceUsage()["memory"],
		"resource_usage_disk":   am.performanceData.GetResourceUsage()["disk"],
	}
}

func (am *AdvancedAutonomyManagerImpl) enrichForecastWithEcosystemData(ctx context.Context, forecast *interfaces.MaintenanceForecast) (*interfaces.MaintenanceForecast, error) {
	// Enrichir la prédiction avec des données de l'écosystème
	// Cette méthode sera complétée avec la logique d'enrichissement
	return forecast, nil
}

func (am *AdvancedAutonomyManagerImpl) calculatePredictionConfidence(forecast *interfaces.MaintenanceForecast) float64 {
	// Calculer la confiance de la prédiction
	return forecast.Confidence
}

func (am *AdvancedAutonomyManagerImpl) generateMaintenanceRecommendations(forecast *interfaces.MaintenanceForecast) []string {
	recommendations := make([]string, 0)

	for _, issue := range forecast.PredictedIssues {
		for _, action := range issue.PreventiveActions {
			recommendations = append(recommendations, action)
		}
	}

	return recommendations
}

// Utility types and functions

// EcosystemMetrics gère les métriques de l'écosystème
type EcosystemMetrics struct {
	StartTime            time.Time
	TotalOperations      int64
	SuccessfulOperations int64
	FailedOperations     int64
	AverageResponseTime  time.Duration
	mutex                sync.RWMutex
}

// NewEcosystemMetrics crée une nouvelle instance de métriques
func NewEcosystemMetrics() *EcosystemMetrics {
	return &EcosystemMetrics{
		StartTime: time.Now(),
	}
}

// IncrementOperation incrémente le compteur d'opérations
func (em *EcosystemMetrics) IncrementOperation(success bool) {
	em.mutex.Lock()
	defer em.mutex.Unlock()

	em.TotalOperations++
	if success {
		em.SuccessfulOperations++
	} else {
		em.FailedOperations++
	}
}

// GetSuccessRate retourne le taux de succès
func (em *EcosystemMetrics) GetSuccessRate() float64 {
	em.mutex.RLock()
	defer em.mutex.RUnlock()

	if em.TotalOperations == 0 {
		return 1.0
	}
	return float64(em.SuccessfulOperations) / float64(em.TotalOperations)
}

// HealthTracker suit la santé des managers
type HealthTracker struct {
	healthHistory map[string][]float64
	lastCheck     time.Time
	mutex         sync.RWMutex
}

// NewHealthTracker crée un nouveau traceur de santé
func NewHealthTracker() *HealthTracker {
	return &HealthTracker{
		healthHistory: make(map[string][]float64),
		lastCheck:     time.Now(),
	}
}

// UpdateHealthMetrics met à jour les métriques de santé
func (ht *HealthTracker) UpdateHealthMetrics(ctx context.Context, managers map[string]interfaces.BaseManager) {
	ht.mutex.Lock()
	defer ht.mutex.Unlock()

	for name, manager := range managers {
		health := 1.0
		if err := manager.HealthCheck(ctx); err != nil {
			health = 0.0
		}

		if ht.healthHistory[name] == nil {
			ht.healthHistory[name] = make([]float64, 0)
		}

		ht.healthHistory[name] = append(ht.healthHistory[name], health)

		// Garder seulement les 100 dernières mesures
		if len(ht.healthHistory[name]) > 100 {
			ht.healthHistory[name] = ht.healthHistory[name][1:]
		}
	}

	ht.lastCheck = time.Now()
}

// GetHealthTrend retourne la tendance de santé pour un manager
func (ht *HealthTracker) GetHealthTrend(managerName string) float64 {
	ht.mutex.RLock()
	defer ht.mutex.RUnlock()

	history, exists := ht.healthHistory[managerName]
	if !exists || len(history) == 0 {
		return 1.0
	}

	total := 0.0
	for _, health := range history {
		total += health
	}

	return total / float64(len(history))
}

// PerformanceData gère les données de performance
type PerformanceData struct {
	responseTimes []time.Duration
	throughput    int64
	successCount  int64
	totalCount    int64
	mutex         sync.RWMutex
}

// NewPerformanceData crée une nouvelle instance de données de performance
func NewPerformanceData() *PerformanceData {
	return &PerformanceData{
		responseTimes: make([]time.Duration, 0),
	}
}

// RecordResponseTime enregistre un temps de réponse
func (pd *PerformanceData) RecordResponseTime(duration time.Duration) {
	pd.mutex.Lock()
	defer pd.mutex.Unlock()

	pd.responseTimes = append(pd.responseTimes, duration)

	// Garder seulement les 1000 dernières mesures
	if len(pd.responseTimes) > 1000 {
		pd.responseTimes = pd.responseTimes[1:]
	}
}

// GetAverageResponseTime retourne le temps de réponse moyen
func (pd *PerformanceData) GetAverageResponseTime() time.Duration {
	pd.mutex.RLock()
	defer pd.mutex.RUnlock()

	if len(pd.responseTimes) == 0 {
		return 0
	}

	total := time.Duration(0)
	for _, rt := range pd.responseTimes {
		total += rt
	}

	return total / time.Duration(len(pd.responseTimes))
}

// GetThroughput retourne le débit
func (pd *PerformanceData) GetThroughput() int64 {
	pd.mutex.RLock()
	defer pd.mutex.RUnlock()

	return pd.throughput
}

// GetSuccessRate retourne le taux de succès
func (pd *PerformanceData) GetSuccessRate() float64 {
	pd.mutex.RLock()
	defer pd.mutex.RUnlock()

	if pd.totalCount == 0 {
		return 1.0
	}

	return float64(pd.successCount) / float64(pd.totalCount)
}

// GetResourceUsage retourne l'utilisation des ressources
func (pd *PerformanceData) GetResourceUsage() map[string]float64 {
	return map[string]float64{
		"cpu":    0.15, // 15% CPU usage
		"memory": 0.25, // 25% memory usage
		"disk":   0.10, // 10% disk usage
	}
}

// IncrementOperation incrémente les compteurs d'opération
func (pd *PerformanceData) IncrementOperation(success bool) {
	pd.mutex.Lock()
	defer pd.mutex.Unlock()

	pd.totalCount++
	if success {
		pd.successCount++
	}
}
