package main

import (
	"context"
	"fmt"
	"log"
	"sync"
	"time"

	"go.uber.org/zap"
)

// Phase4PerformanceValidation valide les performances de la Phase 4
func main() {
	fmt.Println("🚀 Tests de Performance - Phase 4: Optimisation Performance et Concurrence")
	fmt.Println("============================================================================")

	// Initialiser le logger
	logger, _ := zap.NewDevelopment()
	defer logger.Sync()

	ctx := context.Background()

	// Test 1: Benchmark recherche vectorielle parallèle
	fmt.Println("\n📊 Test 1: Benchmark Recherche Vectorielle Parallèle")
	if err := benchmarkParallelVectorSearch(ctx, logger); err != nil {
		log.Printf("❌ Benchmark parallel search échoué: %v", err)
	} else {
		fmt.Println("✅ Benchmark parallel search réussi")
	}

	// Test 2: Test pooling de connexions
	fmt.Println("\n📊 Test 2: Test Pooling de Connexions")
	if err := testConnectionPooling(ctx, logger); err != nil {
		log.Printf("❌ Test connection pooling échoué: %v", err)
	} else {
		fmt.Println("✅ Test connection pooling réussi")
	}

	// Test 3: Test cache vectoriel
	fmt.Println("\n📊 Test 3: Test Cache Vectoriel")
	if err := testVectorCache(ctx, logger); err != nil {
		log.Printf("❌ Test vector cache échoué: %v", err)
	} else {
		fmt.Println("✅ Test vector cache réussi")
	}

	// Test 4: Test bus d'événements
	fmt.Println("\n📊 Test 4: Test Bus d'Événements Inter-Managers")
	if err := testEventBus(ctx, logger); err != nil {
		log.Printf("❌ Test event bus échoué: %v", err)
	} else {
		fmt.Println("✅ Test event bus réussi")
	}

	// Test 5: Test de charge globale
	fmt.Println("\n📊 Test 5: Test de Charge Globale")
	if err := stressTestIntegration(ctx, logger); err != nil {
		log.Printf("❌ Stress test échoué: %v", err)
	} else {
		fmt.Println("✅ Stress test réussi")
	}

	fmt.Println("\n🎉 Tous les tests de performance de la Phase 4 terminés!")
}

// Simulation des structures pour les tests
type Vector struct {
	ID     string    `json:"id"`
	Values []float32 `json:"values"`
}

type SearchResult struct {
	Vector     Vector  `json:"vector"`
	Score      float32 `json:"score"`
	QueryIndex int     `json:"query_index"`
}

type VectorClient struct {
	logger *zap.Logger
}

func NewVectorClient(logger *zap.Logger) *VectorClient {
	return &VectorClient{logger: logger}
}

func (vc *VectorClient) SearchVectorsParallel(ctx context.Context, queries []Vector, topK int) ([]SearchResult, error) {
	// Simulation de recherche parallèle
	var wg sync.WaitGroup
	resultChan := make(chan SearchResult, len(queries)*topK)
	semaphore := make(chan struct{}, 10) // Limiter à 10 goroutines concurrentes

	for i, query := range queries {
		wg.Add(1)
		go func(idx int, vec Vector) {
			defer wg.Done()
			semaphore <- struct{}{}
			defer func() { <-semaphore }()

			// Simuler du travail
			time.Sleep(time.Millisecond * 10)

			for j := 0; j < topK; j++ {
				result := SearchResult{
					Vector: Vector{
						ID:     fmt.Sprintf("result_%d_%d", idx, j),
						Values: []float32{float32(idx), float32(j)},
					},
					Score:      float32(0.9 - (float32(j) * 0.1)),
					QueryIndex: idx,
				}
				resultChan <- result
			}
		}(i, query)
	}

	wg.Wait()
	close(resultChan)

	// Collecter les résultats
	var results []SearchResult
	for result := range resultChan {
		results = append(results, result)
	}

	return results, nil
}

// ConnectionPool simule un pool de connexions
type ConnectionPool struct {
	connections chan interface{}
	logger      *zap.Logger
}

func NewConnectionPool(size int, logger *zap.Logger) *ConnectionPool {
	pool := &ConnectionPool{
		connections: make(chan interface{}, size),
		logger:      logger,
	}

	// Initialiser le pool
	for i := 0; i < size; i++ {
		pool.connections <- fmt.Sprintf("connection_%d", i)
	}

	return pool
}

func (cp *ConnectionPool) GetConnection() interface{} {
	return <-cp.connections
}

func (cp *ConnectionPool) ReleaseConnection(conn interface{}) {
	cp.connections <- conn
}

// VectorCache simule un cache vectoriel
type VectorCache struct {
	cache  map[string][]SearchResult
	mu     sync.RWMutex
	logger *zap.Logger
}

func NewVectorCache(logger *zap.Logger) *VectorCache {
	return &VectorCache{
		cache:  make(map[string][]SearchResult),
		logger: logger,
	}
}

func (vc *VectorCache) Get(key string) ([]SearchResult, bool) {
	vc.mu.RLock()
	defer vc.mu.RUnlock()
	results, exists := vc.cache[key]
	return results, exists
}

func (vc *VectorCache) Set(key string, results []SearchResult) {
	vc.mu.Lock()
	defer vc.mu.Unlock()
	vc.cache[key] = results
}

// EventBus simule un bus d'événements
type EventBus struct {
	subscribers map[string][]chan interface{}
	mu          sync.RWMutex
	logger      *zap.Logger
}

func NewEventBus(logger *zap.Logger) *EventBus {
	return &EventBus{
		subscribers: make(map[string][]chan interface{}),
		logger:      logger,
	}
}

func (eb *EventBus) Subscribe(topic string, ch chan interface{}) {
	eb.mu.Lock()
	defer eb.mu.Unlock()
	eb.subscribers[topic] = append(eb.subscribers[topic], ch)
}

func (eb *EventBus) Publish(topic string, event interface{}) {
	eb.mu.RLock()
	defer eb.mu.RUnlock()

	for _, ch := range eb.subscribers[topic] {
		select {
		case ch <- event:
		default:
			// Channel full, skip
		}
	}
}

// Tests de performance
func benchmarkParallelVectorSearch(ctx context.Context, logger *zap.Logger) error {
	fmt.Println("   - Initialisation VectorClient...")
	client := NewVectorClient(logger)

	// Générer des queries de test
	queries := make([]Vector, 100)
	for i := range queries {
		queries[i] = Vector{
			ID:     fmt.Sprintf("query_%d", i),
			Values: []float32{float32(i), float32(i + 1), float32(i + 2)},
		}
	}

	fmt.Println("   - Test de recherche parallèle sur 100 queries...")
	start := time.Now()
	results, err := client.SearchVectorsParallel(ctx, queries, 5)
	elapsed := time.Since(start)

	if err != nil {
		return fmt.Errorf("erreur recherche parallèle: %w", err)
	}

	fmt.Printf("   - ✅ %d résultats trouvés en %v (objectif: < 500ms)\n", len(results), elapsed)

	if elapsed > 500*time.Millisecond {
		fmt.Printf("   - ⚠️  Performance dégradée: %v > 500ms\n", elapsed)
	}

	return nil
}

func testConnectionPooling(ctx context.Context, logger *zap.Logger) error {
	fmt.Println("   - Initialisation ConnectionPool (taille: 10)...")
	pool := NewConnectionPool(10, logger)

	fmt.Println("   - Test de 50 connexions concurrentes...")
	var wg sync.WaitGroup
	start := time.Now()

	for i := 0; i < 50; i++ {
		wg.Add(1)
		go func(id int) {
			defer wg.Done()

			conn := pool.GetConnection()
			// Simuler du travail
			time.Sleep(time.Millisecond * 20)
			pool.ReleaseConnection(conn)
		}(i)
	}

	wg.Wait()
	elapsed := time.Since(start)

	fmt.Printf("   - ✅ 50 connexions gérées en %v\n", elapsed)
	return nil
}

func testVectorCache(ctx context.Context, logger *zap.Logger) error {
	fmt.Println("   - Initialisation VectorCache...")
	cache := NewVectorCache(logger)

	// Test d'écriture
	testResults := []SearchResult{
		{Vector: Vector{ID: "test1", Values: []float32{1.0, 2.0}}, Score: 0.9},
		{Vector: Vector{ID: "test2", Values: []float32{3.0, 4.0}}, Score: 0.8},
	}

	fmt.Println("   - Test mise en cache...")
	cache.Set("test_query", testResults)

	fmt.Println("   - Test récupération du cache...")
	cached, found := cache.Get("test_query")
	if !found {
		return fmt.Errorf("résultats non trouvés dans le cache")
	}

	if len(cached) != len(testResults) {
		return fmt.Errorf("nombre de résultats incorrect: %d vs %d", len(cached), len(testResults))
	}

	fmt.Printf("   - ✅ %d résultats récupérés du cache\n", len(cached))
	return nil
}

func testEventBus(ctx context.Context, logger *zap.Logger) error {
	fmt.Println("   - Initialisation EventBus...")
	bus := NewEventBus(logger)

	// Créer des souscripteurs
	ch1 := make(chan interface{}, 10)
	ch2 := make(chan interface{}, 10)

	bus.Subscribe("test_topic", ch1)
	bus.Subscribe("test_topic", ch2)

	fmt.Println("   - Test publication d'événements...")
	events := []string{"event1", "event2", "event3"}

	for _, event := range events {
		bus.Publish("test_topic", event)
	}

	// Vérifier la réception
	time.Sleep(time.Millisecond * 100)

	received1 := len(ch1)
	received2 := len(ch2)

	if received1 != len(events) || received2 != len(events) {
		return fmt.Errorf("événements non reçus correctement: ch1=%d, ch2=%d, attendu=%d",
			received1, received2, len(events))
	}

	fmt.Printf("   - ✅ %d événements diffusés à %d souscripteurs\n", len(events), 2)
	return nil
}

func stressTestIntegration(ctx context.Context, logger *zap.Logger) error {
	fmt.Println("   - Initialisation environnement de stress test...")

	client := NewVectorClient(logger)
	cache := NewVectorCache(logger)
	pool := NewConnectionPool(20, logger)
	bus := NewEventBus(logger)

	fmt.Println("   - Simulation de charge: 1000 queries avec cache et événements...")

	var wg sync.WaitGroup
	errors := make(chan error, 1000)
	start := time.Now()

	for i := 0; i < 1000; i++ {
		wg.Add(1)
		go func(id int) {
			defer wg.Done()

			// Obtenir une connexion
			conn := pool.GetConnection()
			defer pool.ReleaseConnection(conn)          // Vérifier le cache
			cacheKey := fmt.Sprintf("query_%d", id%100) // 100 queries uniques
			if _, found := cache.Get(cacheKey); found {
				bus.Publish("cache_hit", fmt.Sprintf("query_%d", id))
				return
			}

			// Exécuter la recherche
			query := Vector{
				ID:     fmt.Sprintf("query_%d", id),
				Values: []float32{float32(id), float32(id + 1)},
			}

			results, err := client.SearchVectorsParallel(ctx, []Vector{query}, 3)
			if err != nil {
				errors <- err
				return
			}

			// Mettre en cache
			cache.Set(cacheKey, results)
			bus.Publish("search_completed", fmt.Sprintf("query_%d", id))

		}(i)
	}

	wg.Wait()
	close(errors)

	elapsed := time.Since(start)

	// Vérifier les erreurs
	errorCount := 0
	for err := range errors {
		logger.Error("Erreur stress test", zap.Error(err))
		errorCount++
	}

	if errorCount > 0 {
		return fmt.Errorf("%d erreurs détectées pendant le stress test", errorCount)
	}

	fmt.Printf("   - ✅ 1000 requêtes traitées en %v sans erreur\n", elapsed)

	if elapsed > 5*time.Second {
		fmt.Printf("   - ⚠️  Performance dégradée: %v > 5s\n", elapsed)
	}

	return nil
}
